{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:45.747729Z",
     "iopub.status.busy": "2022-07-07T11:14:45.747050Z",
     "iopub.status.idle": "2022-07-07T11:14:45.754685Z",
     "shell.execute_reply": "2022-07-07T11:14:45.753045Z",
     "shell.execute_reply.started": "2022-07-07T11:14:45.747620Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:45.756991Z",
     "iopub.status.busy": "2022-07-07T11:14:45.756136Z",
     "iopub.status.idle": "2022-07-07T11:14:48.346415Z",
     "shell.execute_reply": "2022-07-07T11:14:48.344628Z",
     "shell.execute_reply.started": "2022-07-07T11:14:45.756948Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch_scatter\n",
    "import inspect\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.cuda import amp\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.348859Z",
     "iopub.status.busy": "2022-07-07T11:14:48.348458Z",
     "iopub.status.idle": "2022-07-07T11:14:48.386584Z",
     "shell.execute_reply": "2022-07-07T11:14:48.385559Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.348811Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_param(shape):\n",
    "    param = nn.Parameter(torch.Tensor(*shape))\n",
    "    nn.init.xavier_normal_(param.data)\n",
    "    return param\n",
    "def com_mult(a, b):\n",
    "    r1, i1 = a[:, 0], a[:, 1]\n",
    "    r2, i2 = b[:, 0], b[:, 1]\n",
    "    return torch.stack([r1 * r2 - i1 * i2, r1 * i2 + i1 * r2], dim = -1)\n",
    "\n",
    "def conj(a):    \n",
    "    a[:, 1] = -a[:, 1]\n",
    "    return a\n",
    "def ccorr(a, b):\n",
    "    return torch.irfft(com_mult(conj(torch.rfft(a, 1)), torch.rfft(b, 1)), 1, signal_sizes=(a.shape[-1],))\n",
    "\n",
    "class CompGcnBasis(nn.Module):\n",
    "    nodes_dim = 0\n",
    "    head_dim = 0\n",
    "    tail_dim = 1\n",
    "    def __init__(self, in_channels, out_channels, num_relations, num_basis_vector,act = torch.tanh,cache = True,dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_basis_vector = num_basis_vector\n",
    "        self.act = act\n",
    "        self.device = None\n",
    "        self.cache = cache\n",
    "        \n",
    "        #----------- Creating learnable basis vector , shape is (num_basis, feature_size(in channel))\n",
    "        self.basis_vector = get_param((num_basis_vector, in_channels))\n",
    "        # this weight matrix initialize the weight features for each relation(including inverse), shape is (2*num_relations, num_basis)\n",
    "        self.rel_weight = get_param((num_relations*2, self.num_basis_vector))\n",
    "        # this learnable weight matrix is for projection, that project each relation to the same dimension of node_dimension\n",
    "        self.weight_rel = get_param((in_channels,out_channels))\n",
    "        # add another embedding for loop\n",
    "        self.loop_rel = get_param((1,in_channels))\n",
    "        #----------- Creating three updated matrix, as three kind of relations updating, in, out, loop\n",
    "        # using for updating weight\n",
    "        self.w_in = get_param((in_channels,out_channels))\n",
    "        self.w_out = get_param((in_channels,out_channels))\n",
    "        self.w_loop = get_param((in_channels,out_channels))\n",
    "        \n",
    "        # define some helpful parameter\n",
    "        self.in_norm, self.out_norm = None, None\n",
    "        self.in_index, self.out_index = None, None\n",
    "        self.in_type, self.out_type = None, None\n",
    "        self.loop_index, self.loop_type =None, None\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "    def relation_transform(self, entity_embedding, relation_embedding,type_):\n",
    "        '''\n",
    "        This function given entity embedding and relation embedding, in order return three types of \n",
    "        non-parameterized operations, which is subjection, corr, multiplication\n",
    "        '''\n",
    "        assert type_ in [\"mul\",\"sub\",\"corr\"], \"not implemented now\"\n",
    "        if type_ == \"mul\":\n",
    "            out = entity_embedding*relation_embedding\n",
    "        elif type_ == \"sub\":\n",
    "            out = entity_embedding - relation_embedding\n",
    "        else:\n",
    "            out = ccorr(entity_embedding,relation_embedding)\n",
    "        return out\n",
    "    \n",
    "    def normalization(self, edge_index, num_entity):\n",
    "        '''\n",
    "        As normal GCN, this function calculate the normalization adj matrix \n",
    "        '''\n",
    "        head, tail = edge_index\n",
    "        edge_weight = torch.ones_like(head).float()\n",
    "        degree = torch_scatter.scatter_add(edge_weight,head,dim_size=num_entity,dim = self.nodes_dim)\n",
    "        degree_inv = degree.pow(-0.5)\n",
    "        # if inf, in order to prevent nan in scatter function\n",
    "        degree_inv[degree_inv == float(\"inf\")] = 0\n",
    "        norm = degree_inv[head] * edge_weight * degree_inv[tail]\n",
    "        return norm\n",
    "    def scatter_function(self,type_, src, index, dim_size = None):\n",
    "        '''\n",
    "        This function given scatter_ type, which should me max, mean,or sum, given source array, given index array, given dimension size\n",
    "        '''\n",
    "        assert type_.lower() in [\"sum\",\"mean\",\"max\"]\n",
    "        return torch_scatter.scatter(src, index, dim=0,out=None,dim_size = dim_size, reduce= type_)\n",
    "    \n",
    "    def propogating_message(self, method, node_features,edge_index,edge_type, rel_embedding, edge_norm,mode,type_):\n",
    "        '''\n",
    "        This function done the basic aggregation\n",
    "        '''\n",
    "        assert method in [\"sum\", \"mean\", \"max\"]\n",
    "        assert mode in [\"in\",\"out\",\"loop\"]\n",
    "        size = node_features.shape[0]\n",
    "        coresponding_weight = getattr(self, 'w_{}'.format(mode))\n",
    "        #-------------- this index selection: given relation embedding and relation_basic representation, choose the inital basis vector part\n",
    "        relation_embedding = torch.index_select(rel_embedding,dim = 0, index = edge_type)\n",
    "        # ------------- using index of tail in edge index to represent head by relation\n",
    "        node_features = node_features[edge_index[1]]\n",
    "        out = self.relation_transform(node_features, relation_embedding,type_)\n",
    "        out = torch.matmul(out,coresponding_weight)\n",
    "        out = out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "        out = self.scatter_function(method,out,edge_index[0],  size)\n",
    "        return out    \n",
    "    def forward(self, nodes_features, edge_index,edge_type):\n",
    "        '''\n",
    "        Forward propogate function:\n",
    "            Given input nodes_features, adj_matrix, relation_matrix\n",
    "        '''\n",
    "        with amp.autocast():\n",
    "            if self.device is None:\n",
    "                self.device = edge_index.device\n",
    "            # ----------- First done the basis part, which means represent each relation using a vector space defining previously\n",
    "            relation_embedding = torch.mm(self.rel_weight,self.basis_vector)\n",
    "            # ----------- add a self-loop dimension\n",
    "            relation_embedding = torch.cat([relation_embedding,self.loop_rel],dim = 0)\n",
    "            num_edges = edge_index.shape[1]//2\n",
    "            num_nodes = nodes_features.shape[self.nodes_dim]\n",
    "            if not self.cache or self.in_norm == None:\n",
    "                #---------------- in represent in_relation, out represent out_relation\n",
    "                self.in_index, self.out_index = edge_index[:,:num_edges], edge_index[:,num_edges:]\n",
    "                self.in_type, self.out_type = edge_type[:num_edges], edge_type[num_edges:]\n",
    "                # --------------- create self-loop part\n",
    "                self.loop_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)]).to(self.device)\n",
    "                self.loop_type = torch.full((num_nodes,), relation_embedding.shape[0]-1, dtype = torch.long).to(self.device)\n",
    "                # -------------- create normalization part\n",
    "                self.in_norm = self.normalization(self.in_index, num_nodes)\n",
    "                self.out_norm = self.normalization(self.out_index, num_nodes)\n",
    "            #print(self.in_norm.isinf().any())\n",
    "            in_res = self.propogating_message('sum',nodes_features,self.in_index,self.in_type, relation_embedding,self.in_norm,\"in\",\"sub\")\n",
    "            loop_res = self.propogating_message('sum',nodes_features,self.loop_index,self.loop_type, relation_embedding,None,\"loop\",\"sub\")\n",
    "            out_res = self.propogating_message('sum',nodes_features,self.out_index,self.out_type, relation_embedding,self.out_norm,\"out\",\"sub\")\n",
    "            # I don't know why but source code done it\n",
    "            out = self.drop(in_res)*(1/3) + self.drop(out_res)*(1/3) + loop_res*(1/3)\n",
    "            # update the relation embedding\n",
    "            out_2 = torch.matmul(relation_embedding,self.weight_rel)\n",
    "            return self.act(out),out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.390919Z",
     "iopub.status.busy": "2022-07-07T11:14:48.390204Z",
     "iopub.status.idle": "2022-07-07T11:14:48.421574Z",
     "shell.execute_reply": "2022-07-07T11:14:48.420530Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.390873Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompGcn_non_first_layer(nn.Module):\n",
    "    nodes_dim = 0\n",
    "    head_dim = 0\n",
    "    tail_dim = 1\n",
    "    def __init__(self, in_channels, out_channels, num_relations,act = torch.tanh,dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.act = act\n",
    "        self.device = None\n",
    "        \n",
    "        # this learnable weight matrix is for projection, that project each relation to the same dimension of node_dimension\n",
    "        self.weight_rel = get_param((in_channels,out_channels))\n",
    "        # add another embedding for loop\n",
    "        self.loop_rel = get_param((1,in_channels))\n",
    "        #----------- Creating three updated matrix, as three kind of relations updating, in, out, loop\n",
    "        # using for updating weight\n",
    "        self.w_in = get_param((in_channels,out_channels))\n",
    "        self.w_out = get_param((in_channels,out_channels))\n",
    "        self.w_loop = get_param((in_channels,out_channels))\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "    def relation_transform(self, entity_embedding, relation_embedding,type_):\n",
    "        '''\n",
    "        This function given entity embedding and relation embedding, in order return three types of \n",
    "        non-parameterized operations, which is subjection, corr, multiplication\n",
    "        '''\n",
    "        assert type_ in [\"mul\",\"sub\",\"corr\"], \"not implemented now\"\n",
    "        if type_ == \"mul\":\n",
    "            out = entity_embedding*relation_embedding\n",
    "        elif type_ == \"sub\":\n",
    "            out = entity_embedding - relation_embedding\n",
    "        else:\n",
    "            out = ccorr(entity_embedding,relation_embedding)\n",
    "        return out\n",
    "    \n",
    "    def normalization(self, edge_index, num_entity):\n",
    "        '''\n",
    "        As normal GCN, this function calculate the normalization adj matrix \n",
    "        '''\n",
    "        head, tail = edge_index\n",
    "        edge_weight = torch.ones_like(head).float()\n",
    "        degree = torch_scatter.scatter_add(edge_weight,head,dim_size=num_entity,dim = self.nodes_dim)\n",
    "        degree_inv = degree.pow(-0.5)\n",
    "        # if inf, in order to prevent nan in scatter function\n",
    "        degree_inv[degree_inv == float(\"inf\")] = 0\n",
    "        norm = degree_inv[head] * edge_weight * degree_inv[tail]\n",
    "        return norm\n",
    "    def scatter_function(self,type_, src, index, dim_size = None):\n",
    "        '''\n",
    "        This function given scatter_ type, which should me max, mean,or sum, given source array, given index array, given dimension size\n",
    "        '''\n",
    "        assert type_.lower() in [\"sum\",\"mean\",\"max\"]\n",
    "        return torch_scatter.scatter(src, index, dim=0,out=None,dim_size = dim_size, reduce= type_)\n",
    "    \n",
    "    def propogating_message(self, method, node_features,edge_index,edge_type, rel_embedding, edge_norm,mode,type_):\n",
    "        '''\n",
    "        This function done the basic aggregation\n",
    "        '''\n",
    "        assert method in [\"sum\", \"mean\", \"max\"]\n",
    "        assert mode in [\"in\",\"out\",\"loop\"]\n",
    "        size = node_features.shape[0]\n",
    "        coresponding_weight = getattr(self, 'w_{}'.format(mode))\n",
    "        #-------------- this index selection: given relation embedding and relation_basic representation, choose the inital basis vector part\n",
    "        relation_embedding = torch.index_select(rel_embedding,dim = 0, index = edge_type)\n",
    "        # ------------- using index of tail in edge index to represent head by relation\n",
    "        node_features = node_features[edge_index[1]]\n",
    "        out = self.relation_transform(node_features, relation_embedding,type_)\n",
    "        out = torch.matmul(out,coresponding_weight)\n",
    "        out = out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "        out = self.scatter_function(method,out,edge_index[0],  size)\n",
    "        return out    \n",
    "    def forward(self, nodes_features, edge_index,edge_type,relation_embedding):\n",
    "        '''\n",
    "        Forward propogate function:\n",
    "            Given input nodes_features, adj_matrix, relation_matrix\n",
    "        '''\n",
    "        with amp.autocast():\n",
    "            if self.device is None:\n",
    "                self.device = edge_index.device\n",
    "            # ----------- add a self-loop dimension\n",
    "            relation_embedding = torch.cat([relation_embedding,self.loop_rel],dim = 0)\n",
    "            num_edges = edge_index.shape[1]//2\n",
    "            num_nodes = nodes_features.shape[self.nodes_dim]\n",
    "            #---------------- in represent in_relation, out represent out_relation\n",
    "            self.in_index, self.out_index = edge_index[:,:num_edges], edge_index[:,num_edges:]\n",
    "            self.in_type, self.out_type = edge_type[:num_edges], edge_type[num_edges:]\n",
    "            # --------------- create self-loop part\n",
    "            self.loop_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)]).to(self.device)\n",
    "            self.loop_type = torch.full((num_nodes,), relation_embedding.shape[0]-1, dtype = torch.long).to(self.device)\n",
    "            # -------------- create normalization part\n",
    "            self.in_norm = self.normalization(self.in_index, num_nodes)\n",
    "            self.out_norm = self.normalization(self.out_index, num_nodes)\n",
    "            #print(self.in_norm.isinf().any())\n",
    "            in_res = self.propogating_message('sum',nodes_features,self.in_index,self.in_type, relation_embedding,self.in_norm,\"in\",\"sub\")\n",
    "            loop_res = self.propogating_message('sum',nodes_features,self.loop_index,self.loop_type, relation_embedding,None,\"loop\",\"sub\")\n",
    "            out_res = self.propogating_message('sum',nodes_features,self.out_index,self.out_type, relation_embedding,self.out_norm,\"out\",\"sub\")\n",
    "            # I don't know why but source code done it\n",
    "            out = self.drop(in_res)*(1/3) + self.drop(out_res)*(1/3) + loop_res*(1/3)\n",
    "            # update the relation embedding\n",
    "            out_2 = torch.matmul(relation_embedding,self.weight_rel)\n",
    "            return self.act(out),out_2[:-1]# ignoring self loop inserted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.424270Z",
     "iopub.status.busy": "2022-07-07T11:14:48.423185Z",
     "iopub.status.idle": "2022-07-07T11:14:48.442076Z",
     "shell.execute_reply": "2022-07-07T11:14:48.440896Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.424224Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "num_layers = 2\n",
    "for i in range(num_layers):\n",
    "    print(a[i],a[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.444659Z",
     "iopub.status.busy": "2022-07-07T11:14:48.443936Z",
     "iopub.status.idle": "2022-07-07T11:14:48.459652Z",
     "shell.execute_reply": "2022-07-07T11:14:48.458690Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.444616Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompGcn_total(nn.Module):\n",
    "    def __init__(self, channel_ls ,num_relation, num_basis_vector, edge_idx, edge_type,num_layers = 2, basis = False):\n",
    "        '''\n",
    "        Notice that in preprocessing, we assume that the node number will not be changed on the graph, only change relation.\n",
    "        input params:\n",
    "            1. channel_ls: a channel list containing all conv channel\n",
    "            2. num_relation, the number of relations_type for each graph(after preprocessing, should be the same for each graph)\n",
    "            3. num_basis_vector, the first layer basis of first graph.\n",
    "            4. edge_idx, adj matrix \n",
    "            5. edge_type, relation init\n",
    "            6. basis, whether need basis\n",
    "        '''\n",
    "        assert len(channel_ls) == num_layers + 1 , \"channel number should be layer numbers + 1 , got length \"+str(len(channel_ls))+\" with number of layers \"+str(num_layers)\n",
    "        super(CompGcn_total, self).__init__()\n",
    "        self.edge_idx = edge_idx\n",
    "        self.edge_type = edge_type\n",
    "        self.basis = basis\n",
    "        self.GCN_block = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            if basis and i == 0:\n",
    "                self.GCN_block.add_module(\"Basis_conv_layer\",  CompGcnBasis(in_channels = channel_ls[0], out_channels= channel_ls[1],\n",
    "                                                                            num_relations=num_relation,\n",
    "                                                                            num_basis_vector= num_basis_vector)) \n",
    "            else:\n",
    "                self.GCN_block.add_module(\"Conv_layer\"+str(i),CompGcn_non_first_layer(channel_ls[i], channel_ls[i+1], num_relation))\n",
    "    def forward(self, init_features = None, node_embd = None,rel_embd = None,device = None):\n",
    "        with amp.autocast():\n",
    "            for i, blk in enumerate(self.GCN_block):\n",
    "                if self.basis and i == 0:\n",
    "                    node_embd, rel_embd = blk(init_features, self.edge_idx.to(device), self.edge_type.to(device))\n",
    "                else:\n",
    "                    node_embd, rel_embd = blk(node_embd,self.edge_idx.to(device), self.edge_type.to(device), rel_embd)\n",
    "            return node_embd, rel_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.462786Z",
     "iopub.status.busy": "2022-07-07T11:14:48.461957Z",
     "iopub.status.idle": "2022-07-07T11:14:48.496555Z",
     "shell.execute_reply": "2022-07-07T11:14:48.495292Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.462737Z"
    }
   },
   "outputs": [],
   "source": [
    "class Score_func(nn.Module):\n",
    "    \"\"\"\n",
    "        Func:\n",
    "            Contain all the score functions we often meet. Now we finished ConvE, TransE, TransH, DisMult\n",
    "        \n",
    "        Args:\n",
    "            sub_emb: the head embedding (subject)\n",
    "            rel_emb: the relation embedding (relation)\n",
    "            obj_emb: the tail embedding (object)\n",
    "            kernel_size: a tuple. Only when the score function is ConvE, we need it to do the \n",
    "                        convolutional computation. i.e. kernel_size = (hight, width)\n",
    "            func_type: a string indicating the score function we wanna use. default to be \"TransE\"\n",
    "            conv_drop: a list containing floats, indicating the dropout rate we will use in the ConvE. \n",
    "                        If None, set to be all the same as \"dropout\" value. Default to all be the \n",
    "                        tuned parameter in compGCN paper.\n",
    "            conv_bias: whether to use bias. Default to be True\n",
    "            gamma: a float - margin hyperparameter. Only when we use TransE as our score function, we \n",
    "                    need it. Default to be 40.0, the tuned best parameter in compGCN.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sub_emb, rel_emb, obj_emb, func_type=\"transE\", \n",
    "                 kernel_size = None, conv_drop=(0.2, 0.3, 0.2), \n",
    "                 conv_bias=True, gamma=40.0):\n",
    "        # we can't use self.__class__, because it may cause a recursive problem\n",
    "        super(Score_func, self).__init__()\n",
    "        \n",
    "        self.func_type = func_type.lower()\n",
    "        self.gamma     = gamma\n",
    "        self.sub_emb   = sub_emb\n",
    "        self.rel_emb   = rel_emb\n",
    "        self.obj_emb   = obj_emb\n",
    "        \n",
    "        if self.func_type == \"transh\":\n",
    "            self.relation_norm_embedding  = torch.nn.Embedding(num_embeddings=relation_num,\n",
    "                                                              embedding_dim=self.dimension)\n",
    "            self.relation_hyper_embedding = torch.nn.Embedding(num_embeddings=relation_num,\n",
    "                                                               embedding_dim=self.dimension)\n",
    "            self.entity_embedding         = torch.nn.Embedding(num_embeddings=entity_num,\n",
    "                                                               embedding_dim=self.dimension)\n",
    "        \n",
    "        if self.func_type == \"conve\":\n",
    "            assert not kernel_size is None  # to ensure that the kernel size is defined\n",
    "            \n",
    "            if not conv_drop:\n",
    "                self.hidden_drop = [dropout, dropout, dropout]\n",
    "            else:\n",
    "                l = len(hidden_drop)\n",
    "                assert l <= 3  # ensure the length of hidden_drop smaller equal to 3\n",
    "                if l == 1:\n",
    "                    self.conv_drop = [conv_drop[0], conv_drop[0], conv_drop[0]]\n",
    "                elif l == 2:\n",
    "                    self.conv_drop = [conv_drop[0], conv_drop[0], conv_drop[1]]\n",
    "                else:\n",
    "                    self.conv_drop = conv_drop\n",
    "                \n",
    "            \n",
    "            self.kernel_size    = kernel_size\n",
    "            self.bias           = conv_bias\n",
    "            \n",
    "            self.bn0            = torch.nn.BatchNorm2d(1)\n",
    "            self.bn1            = torch.nn.BatchNorm2d(self.out_channels)\n",
    "            self.bn2            = torch.nn.BatchNorm1d(self.kernel_size)\n",
    "\n",
    "            self.hidden_drop    = torch.nn.Dropout(self.conv_drop[0])\n",
    "            self.hidden_drop2   = torch.nn.Dropout(self.conv_drop[1])\n",
    "            self.feature_drop   = torch.nn.Dropout(self.conv_drop[2])\n",
    "            self.m_conv1        = torch.nn.Conv2d(1, out_channels=self.out_channels, \n",
    "                                                  kernel_size=(self.kernel_size, self.kernel_size), \n",
    "                                                  stride=1, padding=0, bias=self.bias)\n",
    "\n",
    "            flat_sz_h           = int(2*self.kernel_size[1]) - self.kernel_size + 1\n",
    "            flat_sz_w           = self.kernel_size[0] - self.kernel_size + 1\n",
    "            self.flat_sz        = flat_sz_h * flat_sz_w * self.out_channels\n",
    "            self.fc             = torch.nn.Linear(self.flat_sz, self.kernel_size)\n",
    "    \n",
    "    def concat(self, e1_embed, rel_embed):\n",
    "        e1_embed    = e1_embed. view(-1, 1, self.p.embed_dim)\n",
    "        rel_embed   = rel_embed.view(-1, 1, self.p.embed_dim)\n",
    "        stack_inp   = torch.cat([e1_embed, rel_embed], 1)\n",
    "        stack_inp   = torch.transpose(stack_inp, 2, 1).reshape((-1, 1, 2*self.p.k_w, self.p.k_h))\n",
    "        return stack_inp\n",
    "    \n",
    "    def projected(self, ent, norm):\n",
    "        norm = F.normalize(norm, p=2, dim=-1)\n",
    "        return ent - torch.sum(ent * norm, dim = 1, keepdim=True) * norm\n",
    "    \n",
    "    def forward_score(self):\n",
    "        if   self.func_type == \"transe\":\n",
    "            x        = self.sub_emb + self.rel_emb - self.obj_emb\n",
    "        elif self.func_type == \"transh\":\n",
    "            head       = self.entity_embedding(self.sub_emb)\n",
    "            tail       = self.entity_embedding(self.obj_emb)\n",
    "            r_norm     = self.relation_norm_embedding(self.rel_emb)\n",
    "            r_hyper    = self.relation_hyper_embedding(self.rel_emb)\n",
    "            head_hyper = self.projected(head, r_norm)\n",
    "            tail_hyper = self.projected(tail, r_norm)\n",
    "            x          = torch.norm(head_hyper + r_hyper - tail_hyper, p=2, dim=2)\n",
    "        elif self.func_type == \"distmult\":\n",
    "            x        =   torch.mm(self.sub_emb + self.rel_emb, self.obj_emb.transpose(1, 0))\n",
    "            x        +=  self.bias.expand_as(x)\n",
    "        elif self.func_type == \"conve\":\n",
    "            stk_inp  = self.concat(sub_emb, rel_emb)\n",
    "            x        = self.bn0(stk_inp)\n",
    "            x        = self.m_conv1(x)\n",
    "            x        = self.bn1(x)\n",
    "            x        = F.relu(x)\n",
    "            x        = self.feature_drop(x)\n",
    "            x        = x.view(-1, self.flat_sz)\n",
    "            x        = self.fc(x)\n",
    "            x        = self.hidden_drop2(x)\n",
    "            x        = self.bn2(x)\n",
    "            x        = F.relu(x)\n",
    "\n",
    "            x = torch.mm(x, self.obj_emb.transpose(1,0))\n",
    "            x += self.bias.expand_as(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.498834Z",
     "iopub.status.busy": "2022-07-07T11:14:48.498260Z",
     "iopub.status.idle": "2022-07-07T11:14:48.553349Z",
     "shell.execute_reply": "2022-07-07T11:14:48.551137Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.498789Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompGcn_with_temporal(nn.Module):\n",
    "    def __init__(self, conv_dim, num_relation, num_entity,node_dim, num_hiddens ,num_basis_vector, edge_idx, edge_type, num_class,time_stamp = 2,\n",
    "                 num_layers = 2,score_func=\"TransE\"):\n",
    "        '''\n",
    "        Notice that in preprocessing, we assume that the node number will not be changed on the graph, only change relation.\n",
    "        input params:\n",
    "            1. conv_dim, a list of tuple, [(channel 1, channel2, channel 3), (channel 3, channel 4, channel 5),...]\n",
    "            2. num_layer, number of CompGCN layer, now assume to 2 per graph\n",
    "            3. num_relation, the number of relations_type for each graph(after preprocessing, should be the same for each graph)\n",
    "            4. num_entity, number of entity, should be the same for each graph\n",
    "            5. node_dimension, dimension of nodes\n",
    "            6. num_basis_vector, the first layer basis of first graph.\n",
    "            7. edge_idx, a list of edge_idx\n",
    "            8. edge_type, a list of edge_type\n",
    "            9. num_class, classification number \n",
    "            10. time stamp: How many time steps \n",
    "        '''\n",
    "        assert len(conv_dim) == time_stamp, \"time stamp length should be the same as number of convloution dimension list!, got time stamp \"+str(time_stamp)+\" with conv_dim \"+str(len(conv_dim))\n",
    "        assert len(edge_idx) == len(edge_type) == len(conv_dim) == time_stamp, \"Number of KG mismatched with time stamp!\"\n",
    "        super(CompGcn_with_temporal,self).__init__()\n",
    "        self.num_relation = num_relation\n",
    "        self.node_features = get_param(shape= (num_entity,node_dim))\n",
    "        assert node_dim == conv_dim[0][0]\n",
    "        self.temporal_blk = nn.Sequential()\n",
    "        for i in range(time_stamp):\n",
    "            if i == 0:\n",
    "                self.temporal_blk.add_module(\"Temporal block Basis\" , CompGcn_total(conv_dim[i], num_relation, num_basis_vector, \n",
    "                                                                                 edge_idx[i], edge_type[i], num_layers,True))\n",
    "            else:\n",
    "                self.temporal_blk.add_module(\"Temporal block\" + str(i), CompGcn_total(conv_dim[i], num_relation, num_basis_vector, \n",
    "                                                                                 edge_idx[i], edge_type[i], num_layers,False))\n",
    "\n",
    "        # change bert input to same as before\n",
    "        self.ln1 = nn.Linear(conv_dim[-1][-1], num_class)\n",
    "        self.dropout_node = nn.Dropout(0.2)\n",
    "        self.dropout_rel = nn.Dropout(0.2)\n",
    "        self.ln1 = self.func_init(self.ln1)\n",
    "        self.score = score_func\n",
    "        # add GRU \n",
    "        self.W_xr = nn.Linear(conv_dim[0][-1],num_hiddens)\n",
    "        self.W_xz = nn.Linear(conv_dim[0][-1],num_hiddens)\n",
    "        self.W_xh = nn.Linear(conv_dim[0][-1],num_hiddens)\n",
    "        self.W_hr = nn.Linear(num_hiddens,num_hiddens, bias = True)\n",
    "        self.W_hz = nn.Linear(num_hiddens,num_hiddens, bias = True)\n",
    "        self.W_hh = nn.Linear(num_hiddens,num_hiddens, bias = True)\n",
    "        self.act_update = nn.Sigmoid()\n",
    "        self.act_hidden = nn.Tanh()\n",
    "        self.act_reset = nn.Sigmoid()\n",
    "    def func_init(self,m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        return m\n",
    "    def init_state(self, device):\n",
    "        return torch.zeros(self.num_relation * 2 + 1, conv_dim[1][0], device = device)\n",
    "    def forward(self, head_index, tail_index, rel_index, state):\n",
    "        '''\n",
    "        Node index and rel index are corresponding information in a batch for bert part, we only care about the node, edge relation in a batch.\n",
    "        Since the embedding is tail - relation to head, the source will be tail, target will be head\n",
    "        '''\n",
    "        with amp.autocast():\n",
    "            device = self.node_features.device\n",
    "            for i, blk in enumerate(self.temporal_blk):\n",
    "                if i == 0:\n",
    "                    node_embd, rel_embd = blk(self.node_features, device = device)\n",
    "                else:\n",
    "                    node_embd, rel_embd = blk(node_embd = node_embd, rel_embd = rel_embd,device = device)\n",
    "                # with GRU\n",
    "                node_embd, rel_embd = self.dropout_node(node_embd), self.dropout_rel(rel_embd)\n",
    "                Z = self.act_update(self.W_xz(rel_embd) + self.W_hz(state))\n",
    "                R = self.act_reset(self.W_xr(rel_embd) + self.W_hr(state))\n",
    "                H_candidate = self.act_hidden(self.W_xh(rel_embd) + self.W_hh(R * state))\n",
    "                state = Z * state + (1 - Z) * H_candidate\n",
    "            # then choose corresponding index out:\n",
    "            # shape should be (len(index), hidden_out)\n",
    "            hidden_node_state = node_embd[tail_index,:]\n",
    "            hidden_rel_state  = rel_embd[rel_index,:]\n",
    "            hidden_target_state = node_embd[head_index,:]\n",
    "            head, rel, tail      = (\n",
    "                                        hidden_node_state, \n",
    "                                        hidden_rel_state, \n",
    "                                        hidden_target_state\n",
    "                                   )\n",
    "            score                = Score_func(head, rel, tail, func_type=self.score)\n",
    "            score                = score.forward_score()\n",
    "            score = self.ln1(score)\n",
    "        return score # hidden_node_state, hidden_rel_state, hidden_target_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.561883Z",
     "iopub.status.busy": "2022-07-07T11:14:48.561322Z",
     "iopub.status.idle": "2022-07-07T11:14:48.585578Z",
     "shell.execute_reply": "2022-07-07T11:14:48.584349Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.561787Z"
    }
   },
   "outputs": [],
   "source": [
    "class language_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        '''\n",
    "        df is dataframe given previously\n",
    "        '''\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        This function will return the index\n",
    "        '''\n",
    "        return torch.tensor(self.df.iloc[idx][\"labels\"]), self.df.iloc[idx][\"index_where\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.589235Z",
     "iopub.status.busy": "2022-07-07T11:14:48.587794Z",
     "iopub.status.idle": "2022-07-07T11:14:48.625679Z",
     "shell.execute_reply": "2022-07-07T11:14:48.623049Z",
     "shell.execute_reply.started": "2022-07-07T11:14:48.589189Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "# In[ ]:\n",
    "def train_with_amp(net, train_set, criterion, optimizer, epochs,batch_size, scheduler, gradient_accumulate_step, max_grad_norm , num_gpu):\n",
    "    net.train()\n",
    "    # instantiate a scalar object \n",
    "    ls = []\n",
    "    device = [try_gpu(i) for i in range(num_gpu)]\n",
    "    print(\"train on \" + str(device))\n",
    "    enable_amp = True if \"cuda\" in device[0].type else False\n",
    "    scaler = amp.GradScaler(enabled= enable_amp)\n",
    "    net.to(device[0])\n",
    "    global_step = 0\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        for idx, value in enumerate(train_iter):\n",
    "            labels, index = value\n",
    "            labels = labels.to(device[0])\n",
    "            head_values = torch.tensor(index[0]).to(device[0])\n",
    "            tail_values = torch.tensor(index[2]).to(device[0])\n",
    "            rel_values = torch.tensor(index[1]).to(device[0])\n",
    "            state = net.init_state(device[0])\n",
    "            # when forward process, use amp\n",
    "            with amp.autocast(enabled= enable_amp):\n",
    "                output = net(head_values,tail_values, rel_values, state)  \n",
    "            loss = criterion(output, labels.view(-1,1).float())\n",
    "            # prevent gradient to 0\n",
    "            if gradient_accumulate_step > 1:\n",
    "                # 如果显存不足，通过 gradient_accumulate 来解决\n",
    "                loss = loss/gradient_accumulate_step\n",
    "            \n",
    "            # 放大梯度，避免其消失\n",
    "            scaler.scale(loss).backward()\n",
    "            # do the gradient clip\n",
    "            gradient_norm = nn.utils.clip_grad_norm_(net.parameters(),max_grad_norm)\n",
    "            if (idx + 1) % gradient_accumulate_step == 0:\n",
    "                # 多少 step 更新一次梯度\n",
    "                # 通过 scaler.step 来unscale 回梯度值， 如果气结果不是infs 和Nans， 调用optimizer.step()来更新权重\n",
    "                # 否则忽略step调用， 保证权重不更新\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                scheduler.step()\n",
    "                print(\"done one train\")\n",
    "            # 每100次计算 print 出一次loss\n",
    "            if idx % 1000 == 0 or idx == len(train_iter) -1:\n",
    "                with torch.no_grad():\n",
    "                    print(\"==============Epochs \"+ str(epoch) + \" ======================\")\n",
    "                    print(\"loss: \" + str(loss) + \"; grad_norm: \" + str(gradient_norm))\n",
    "                torch.save({'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss},\"./checkpoint.params\")\n",
    "                ls.append(loss.item())\n",
    "                #print(\"successfully done one train\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.plot(ls)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T11:14:48.630633Z",
     "iopub.status.busy": "2022-07-07T11:14:48.629527Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    edge_idx_1 = torch.tensor(np.load(\"../input/3-graphs-info/edge_idx0.npz\")[\"arr_0\"])\n",
    "    edge_idx_2 = torch.tensor(np.load(\"../input/3-graphs-info/edge_idx1.npz\")[\"arr_0\"])\n",
    "    edge_idx_3 = torch.tensor(np.load(\"../input/3-graphs-info/edge_idx2.npz\")[\"arr_0\"])\n",
    "    num_nodes_0 = torch.tensor(np.load(\"../input/3-graphs-info/graph_0_num_nodes.npz\")[\"arr_0\"])\n",
    "    num_nodes_1 = torch.tensor(np.load(\"../input/3-graphs-info/graph_1_num_nodes.npz\")[\"arr_0\"])\n",
    "    num_nodes_2 = torch.tensor(np.load(\"../input/3-graphs-info/graph_2_num_nodes.npz\")[\"arr_0\"])\n",
    "    num_relation_0 = torch.tensor(np.load(\"../input/3-graphs-info/graph_0_num_edges.npz\")[\"arr_0\"])\n",
    "    num_relation_1 = torch.tensor(np.load(\"../input/3-graphs-info/graph_1_num_edges.npz\")[\"arr_0\"])\n",
    "    num_relation_2 = torch.tensor(np.load(\"../input/3-graphs-info/graph_2_num_edges.npz\")[\"arr_0\"])\n",
    "    edge_type_0 = torch.tensor(np.load(\"../input/3-graphs-info/edge_type0.npz\")[\"arr_0\"])\n",
    "    edge_type_1 = torch.tensor(np.load(\"../input/3-graphs-info/edge_type1.npz\")[\"arr_0\"])\n",
    "    edge_type_2 = torch.tensor(np.load(\"../input/3-graphs-info/edge_type2.npz\")[\"arr_0\"])\n",
    "    head2idx = np.load('../input/3-graphs-info/graph_2entity2index.npy', allow_pickle=True).item()\n",
    "    rel2idx =  np.load('../input/3-graphs-info/graph_2rel2index.npy', allow_pickle=True).item()\n",
    "    num_hiddens = 16\n",
    "    conv_dim, num_layer, node_dim, num_basis, edge_idx, edge_type = [[16, 32, num_hiddens], [16,32, num_hiddens], [16,32, num_hiddens]], 2, 16, 37, [edge_idx_1,edge_idx_2,edge_idx_3],[edge_type_0,edge_type_1,edge_type_2]\n",
    "    tmp = CompGcn_with_temporal(conv_dim,num_relation_2, num_nodes_2+1, node_dim, num_hiddens,num_basis,edge_idx, edge_type,1,3)\n",
    "    train = pd.read_csv(\"../input/train-valid-test-dataset/train.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
    "    train[\"index_where\"] = train[\"index_where\"].apply(ast.literal_eval)\n",
    "    train_set = language_Dataset(train)\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    batch_size = 2\n",
    "    lr = 2e-6\n",
    "    num_gpu = 1\n",
    "    optimizer = torch.optim.AdamW(tmp.parameters(), lr = lr)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer= optimizer, num_warmup_steps = 0, num_training_steps= len(torch.utils.data.DataLoader(train_set, batch_size = batch_size)), num_cycles = 0.5)\n",
    "    train_with_amp(tmp, train_set, loss,optimizer,3,batch_size, scheduler,1,1000, num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = [try_gpu(i) for i in range(num_gpu)]\n",
    "# train_iter = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
    "# labels, index = next(iter(train_iter))\n",
    "# labels = labels.to(device[0])\n",
    "# head_values = torch.tensor(index[0]).to(device[0])\n",
    "# tail_values = torch.tensor(index[2]).to(device[0])\n",
    "# rel_values = torch.tensor(index[1]).to(device[0])\n",
    "# # when forward process, use amp\n",
    "# state = tmp.init_state(device[0])\n",
    "# tmp.to(device[0])\n",
    "# with amp.autocast(enabled= True):\n",
    "#     output = tmp(head_values,tail_values, rel_values, state)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
