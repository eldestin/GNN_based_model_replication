{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-01T03:48:42.187098Z",
     "iopub.status.busy": "2022-05-01T03:48:42.186849Z",
     "iopub.status.idle": "2022-05-01T03:48:42.192198Z",
     "shell.execute_reply": "2022-05-01T03:48:42.191477Z",
     "shell.execute_reply.started": "2022-05-01T03:48:42.187071Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch_scatter\n",
    "import inspect\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.cuda import amp\n",
    "import ast\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:36:06.93728Z",
     "iopub.status.busy": "2022-05-01T03:36:06.937028Z",
     "iopub.status.idle": "2022-05-01T03:44:32.04599Z",
     "shell.execute_reply": "2022-05-01T03:44:32.045121Z",
     "shell.execute_reply.started": "2022-05-01T03:36:06.93725Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch-scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create For basic learnable parameter, can be weighted matrix or basis vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:46:59.57324Z",
     "iopub.status.busy": "2022-05-01T03:46:59.572664Z",
     "iopub.status.idle": "2022-05-01T03:46:59.581197Z",
     "shell.execute_reply": "2022-05-01T03:46:59.580249Z",
     "shell.execute_reply.started": "2022-05-01T03:46:59.573201Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_param(shape):\n",
    "    param = nn.Parameter(torch.Tensor(*shape))\n",
    "    nn.init.xavier_normal_(param.data)\n",
    "    return param\n",
    "def com_mult(a, b):\n",
    "    r1, i1 = a[:, 0], a[:, 1]\n",
    "    r2, i2 = b[:, 0], b[:, 1]\n",
    "    return torch.stack([r1 * r2 - i1 * i2, r1 * i2 + i1 * r2], dim = -1)\n",
    "\n",
    "def conj(a):    \n",
    "    a[:, 1] = -a[:, 1]\n",
    "    return a\n",
    "def ccorr(a, b):\n",
    "    return torch.irfft(com_mult(conj(torch.rfft(a, 1)), torch.rfft(b, 1)), 1, signal_sizes=(a.shape[-1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:00.404222Z",
     "iopub.status.busy": "2022-05-01T03:47:00.403821Z",
     "iopub.status.idle": "2022-05-01T03:47:00.43485Z",
     "shell.execute_reply": "2022-05-01T03:47:00.434134Z",
     "shell.execute_reply.started": "2022-05-01T03:47:00.404187Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompGcnBasis(nn.Module):\n",
    "    nodes_dim = 0\n",
    "    head_dim = 0\n",
    "    tail_dim = 1\n",
    "    def __init__(self, in_channels, out_channels, num_relations, num_basis_vector,act = torch.tanh,cache = True,dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_basis_vector = num_basis_vector\n",
    "        self.act = act\n",
    "        self.device = None\n",
    "        self.cache = cache\n",
    "        \n",
    "        #----------- Creating learnable basis vector , shape is (num_basis, feature_size(in channel))\n",
    "        self.basis_vector = get_param((num_basis_vector, in_channels))\n",
    "        # this weight matrix initialize the weight features for each relation(including inverse), shape is (2*num_relations, num_basis)\n",
    "        self.rel_weight = get_param((num_relations*2, self.num_basis_vector))\n",
    "        # this learnable weight matrix is for projection, that project each relation to the same dimension of node_dimension\n",
    "        self.weight_rel = get_param((in_channels,out_channels))\n",
    "        # add another embedding for loop\n",
    "        self.loop_rel = get_param((1,in_channels))\n",
    "        #----------- Creating three updated matrix, as three kind of relations updating, in, out, loop\n",
    "        # using for updating weight\n",
    "        self.w_in = get_param((in_channels,out_channels))\n",
    "        self.w_out = get_param((in_channels,out_channels))\n",
    "        self.w_loop = get_param((in_channels,out_channels))\n",
    "        \n",
    "        # define some helpful parameter\n",
    "        self.in_norm, self.out_norm = None, None\n",
    "        self.in_index, self.out_index = None, None\n",
    "        self.in_type, self.out_type = None, None\n",
    "        self.loop_index, self.loop_type =None, None\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "    def relation_transform(self, entity_embedding, relation_embedding,type_):\n",
    "        '''\n",
    "        This function given entity embedding and relation embedding, in order return three types of \n",
    "        non-parameterized operations, which is subjection, corr, multiplication\n",
    "        '''\n",
    "        assert type_ in [\"mul\",\"sub\",\"corr\"], \"not implemented now\"\n",
    "        if type_ == \"mul\":\n",
    "            out = entity_embedding*relation_embedding\n",
    "        elif type_ == \"sub\":\n",
    "            out = entity_embedding - relation_embedding\n",
    "        else:\n",
    "            out = ccorr(entity_embedding,relation_embedding)\n",
    "        return out\n",
    "    \n",
    "    def normalization(self, edge_index, num_entity):\n",
    "        '''\n",
    "        As normal GCN, this function calculate the normalization adj matrix \n",
    "        '''\n",
    "        head, tail = edge_index\n",
    "        edge_weight = torch.ones_like(head).float()\n",
    "        degree = torch_scatter.scatter_add(edge_weight,head,dim_size=num_entity,dim = self.nodes_dim)\n",
    "        degree_inv = degree.pow(-0.5)\n",
    "        # if inf, in order to prevent nan in scatter function\n",
    "        degree_inv[degree_inv == float(\"inf\")] = 0\n",
    "        norm = degree_inv[head] * edge_weight * degree_inv[tail]\n",
    "        return norm\n",
    "    def scatter_function(self,type_, src, index, dim_size = None):\n",
    "        '''\n",
    "        This function given scatter_ type, which should me max, mean,or sum, given source array, given index array, given dimension size\n",
    "        '''\n",
    "        assert type_.lower() in [\"sum\",\"mean\",\"max\"]\n",
    "        return torch_scatter.scatter(src, index, dim=0,out=None,dim_size = dim_size, reduce= type_)\n",
    "    \n",
    "    def propogating_message(self, method, node_features,edge_index,edge_type, rel_embedding, edge_norm,mode,type_):\n",
    "        '''\n",
    "        This function done the basic aggregation\n",
    "        '''\n",
    "        assert method in [\"sum\", \"mean\", \"max\"]\n",
    "        assert mode in [\"in\",\"out\",\"loop\"]\n",
    "        size = node_features.shape[0]\n",
    "        coresponding_weight = getattr(self, 'w_{}'.format(mode))\n",
    "        #-------------- this index selection: given relation embedding and relation_basic representation, choose the inital basis vector part\n",
    "        relation_embedding = torch.index_select(rel_embedding,dim = 0, index = edge_type)\n",
    "        # ------------- using index of tail in edge index to represent head by relation\n",
    "        node_features = node_features[edge_index[1]]\n",
    "        out = self.relation_transform(node_features, relation_embedding,type_)\n",
    "        out = torch.matmul(out,coresponding_weight)\n",
    "        out = out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "        out = self.scatter_function(method,out,edge_index[0],  size)\n",
    "        return out    \n",
    "    def forward(self, nodes_features, edge_index,edge_type):\n",
    "        '''\n",
    "        Forward propogate function:\n",
    "            Given input nodes_features, adj_matrix, relation_matrix\n",
    "        '''\n",
    "        with amp.autocast():\n",
    "            if self.device is None:\n",
    "                self.device = edge_index.device\n",
    "            # ----------- First done the basis part, which means represent each relation using a vector space defining previously\n",
    "            relation_embedding = torch.mm(self.rel_weight,self.basis_vector)\n",
    "            # ----------- add a self-loop dimension\n",
    "            relation_embedding = torch.cat([relation_embedding,self.loop_rel],dim = 0)\n",
    "            num_edges = edge_index.shape[1]//2\n",
    "            num_nodes = nodes_features.shape[self.nodes_dim]\n",
    "            if not self.cache or self.in_norm == None:\n",
    "                #---------------- in represent in_relation, out represent out_relation\n",
    "                self.in_index, self.out_index = edge_index[:,:num_edges], edge_index[:,num_edges:]\n",
    "                self.in_type, self.out_type = edge_type[:num_edges], edge_type[num_edges:]\n",
    "                # --------------- create self-loop part\n",
    "                self.loop_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)]).to(self.device)\n",
    "                self.loop_type = torch.full((num_nodes,), relation_embedding.shape[0]-1, dtype = torch.long).to(self.device)\n",
    "                # -------------- create normalization part\n",
    "                self.in_norm = self.normalization(self.in_index, num_nodes)\n",
    "                self.out_norm = self.normalization(self.out_index, num_nodes)\n",
    "            #print(self.in_norm.isinf().any())\n",
    "            in_res = self.propogating_message('sum',nodes_features,self.in_index,self.in_type, relation_embedding,self.in_norm,\"in\",\"sub\")\n",
    "            loop_res = self.propogating_message('sum',nodes_features,self.loop_index,self.loop_type, relation_embedding,None,\"loop\",\"sub\")\n",
    "            out_res = self.propogating_message('sum',nodes_features,self.out_index,self.out_type, relation_embedding,self.out_norm,\"out\",\"sub\")\n",
    "            # I don't know why but source code done it\n",
    "            out = self.drop(in_res)*(1/3) + self.drop(out_res)*(1/3) + loop_res*(1/3)\n",
    "            # update the relation embedding\n",
    "            out_2 = torch.matmul(relation_embedding,self.weight_rel)\n",
    "            return self.act(out),out_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check some stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:01.689476Z",
     "iopub.status.busy": "2022-05-01T03:47:01.689009Z",
     "iopub.status.idle": "2022-05-01T03:47:01.728622Z",
     "shell.execute_reply": "2022-05-01T03:47:01.72766Z",
     "shell.execute_reply.started": "2022-05-01T03:47:01.689431Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompGcn_non_first_layer(nn.Module):\n",
    "    nodes_dim = 0\n",
    "    head_dim = 0\n",
    "    tail_dim = 1\n",
    "    def __init__(self, in_channels, out_channels, num_relations,act = torch.tanh,dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.act = act\n",
    "        self.device = None\n",
    "        \n",
    "        # this learnable weight matrix is for projection, that project each relation to the same dimension of node_dimension\n",
    "        self.weight_rel = get_param((in_channels,out_channels))\n",
    "        # add another embedding for loop\n",
    "        self.loop_rel = get_param((1,in_channels))\n",
    "        #----------- Creating three updated matrix, as three kind of relations updating, in, out, loop\n",
    "        # using for updating weight\n",
    "        self.w_in = get_param((in_channels,out_channels))\n",
    "        self.w_out = get_param((in_channels,out_channels))\n",
    "        self.w_loop = get_param((in_channels,out_channels))\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "    def relation_transform(self, entity_embedding, relation_embedding,type_):\n",
    "        '''\n",
    "        This function given entity embedding and relation embedding, in order return three types of \n",
    "        non-parameterized operations, which is subjection, corr, multiplication\n",
    "        '''\n",
    "        assert type_ in [\"mul\",\"sub\",\"corr\"], \"not implemented now\"\n",
    "        if type_ == \"mul\":\n",
    "            out = entity_embedding*relation_embedding\n",
    "        elif type_ == \"sub\":\n",
    "            out = entity_embedding - relation_embedding\n",
    "        else:\n",
    "            out = ccorr(entity_embedding,relation_embedding)\n",
    "        return out\n",
    "    \n",
    "    def normalization(self, edge_index, num_entity):\n",
    "        '''\n",
    "        As normal GCN, this function calculate the normalization adj matrix \n",
    "        '''\n",
    "        head, tail = edge_index\n",
    "        edge_weight = torch.ones_like(head).float()\n",
    "        degree = torch_scatter.scatter_add(edge_weight,head,dim_size=num_entity,dim = self.nodes_dim)\n",
    "        degree_inv = degree.pow(-0.5)\n",
    "        # if inf, in order to prevent nan in scatter function\n",
    "        degree_inv[degree_inv == float(\"inf\")] = 0\n",
    "        norm = degree_inv[head] * edge_weight * degree_inv[tail]\n",
    "        return norm\n",
    "    def scatter_function(self,type_, src, index, dim_size = None):\n",
    "        '''\n",
    "        This function given scatter_ type, which should me max, mean,or sum, given source array, given index array, given dimension size\n",
    "        '''\n",
    "        assert type_.lower() in [\"sum\",\"mean\",\"max\"]\n",
    "        return torch_scatter.scatter(src, index, dim=0,out=None,dim_size = dim_size, reduce= type_)\n",
    "    \n",
    "    def propogating_message(self, method, node_features,edge_index,edge_type, rel_embedding, edge_norm,mode,type_):\n",
    "        '''\n",
    "        This function done the basic aggregation\n",
    "        '''\n",
    "        assert method in [\"sum\", \"mean\", \"max\"]\n",
    "        assert mode in [\"in\",\"out\",\"loop\"]\n",
    "        size = node_features.shape[0]\n",
    "        coresponding_weight = getattr(self, 'w_{}'.format(mode))\n",
    "        #-------------- this index selection: given relation embedding and relation_basic representation, choose the inital basis vector part\n",
    "        relation_embedding = torch.index_select(rel_embedding,dim = 0, index = edge_type)\n",
    "        # ------------- using index of tail in edge index to represent head by relation\n",
    "        node_features = node_features[edge_index[1]]\n",
    "        out = self.relation_transform(node_features, relation_embedding,type_)\n",
    "        out = torch.matmul(out,coresponding_weight)\n",
    "        out = out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "        out = self.scatter_function(method,out,edge_index[0],  size)\n",
    "        return out    \n",
    "    def forward(self, nodes_features, edge_index,edge_type,relation_embedding):\n",
    "        '''\n",
    "        Forward propogate function:\n",
    "            Given input nodes_features, adj_matrix, relation_matrix\n",
    "        '''\n",
    "        with amp.autocast():\n",
    "            if self.device is None:\n",
    "                self.device = edge_index.device\n",
    "            # ----------- add a self-loop dimension\n",
    "            relation_embedding = torch.cat([relation_embedding,self.loop_rel],dim = 0)\n",
    "            num_edges = edge_index.shape[1]//2\n",
    "            num_nodes = nodes_features.shape[self.nodes_dim]\n",
    "            #---------------- in represent in_relation, out represent out_relation\n",
    "            self.in_index, self.out_index = edge_index[:,:num_edges], edge_index[:,num_edges:]\n",
    "            self.in_type, self.out_type = edge_type[:num_edges], edge_type[num_edges:]\n",
    "            # --------------- create self-loop part\n",
    "            self.loop_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)]).to(self.device)\n",
    "            self.loop_type = torch.full((num_nodes,), relation_embedding.shape[0]-1, dtype = torch.long).to(self.device)\n",
    "            # -------------- create normalization part\n",
    "            self.in_norm = self.normalization(self.in_index, num_nodes)\n",
    "            self.out_norm = self.normalization(self.out_index, num_nodes)\n",
    "            #print(self.in_norm.isinf().any())\n",
    "            in_res = self.propogating_message('sum',nodes_features,self.in_index,self.in_type, relation_embedding,self.in_norm,\"in\",\"sub\")\n",
    "            loop_res = self.propogating_message('sum',nodes_features,self.loop_index,self.loop_type, relation_embedding,None,\"loop\",\"sub\")\n",
    "            out_res = self.propogating_message('sum',nodes_features,self.out_index,self.out_type, relation_embedding,self.out_norm,\"out\",\"sub\")\n",
    "            # I don't know why but source code done it\n",
    "            out = self.drop(in_res)*(1/3) + self.drop(out_res)*(1/3) + loop_res*(1/3)\n",
    "            # update the relation embedding\n",
    "            out_2 = torch.matmul(relation_embedding,self.weight_rel)\n",
    "            return self.act(out),out_2[:-1]# ignoring self loop inserted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CompGCN total + score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:02.251503Z",
     "iopub.status.busy": "2022-05-01T03:47:02.251072Z",
     "iopub.status.idle": "2022-05-01T03:47:02.269113Z",
     "shell.execute_reply": "2022-05-01T03:47:02.268374Z",
     "shell.execute_reply.started": "2022-05-01T03:47:02.25146Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompGcn_total(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel,num_relation, num_basis_vector, edge_idx, edge_type, basis = False):\n",
    "        '''\n",
    "        Notice that in preprocessing, we assume that the node number will not be changed on the graph, only change relation.\n",
    "        input params:\n",
    "            1. conv_dim, a list/tuple that include the convolution in_channel, out_channel, like [[in_1, out_1], [out_1, out_2]]. Assume that each graph has the same dim\n",
    "            2. num_relation, the number of relations_type for each graph(after preprocessing, should be the same for each graph)\n",
    "            3. num_basis_vector, the first layer basis of first graph.\n",
    "            4. edge_idx, adj matrix \n",
    "            5. edge_type, relation init\n",
    "            6. basis, whether need basis\n",
    "        '''\n",
    "        super().__init__()\n",
    "        #assert node_dim == in_channel\n",
    "#         self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.edge_idx = edge_idx\n",
    "        self.edge_type = edge_type\n",
    "        self.basis = basis\n",
    "        if basis:\n",
    "            self.conv1 = CompGcnBasis(in_channels = in_channel, out_channels= out_channel, num_relations=num_relation, num_basis_vector= num_basis_vector)\n",
    "            self.conv2 = CompGcn_non_first_layer(out_channel, out_channel, num_relation)\n",
    "        else:\n",
    "            self.conv1 = CompGcn_non_first_layer(in_channel, out_channel, num_relation)\n",
    "            self.conv2 = CompGcn_non_first_layer(out_channel, out_channel, num_relation)\n",
    "    def forward(self, init_features = None, node_embeding = None,rel_embeding = None,device = None):\n",
    "        with amp.autocast():\n",
    "            if self.basis:\n",
    "                node_embd, rel_embd = self.conv1(init_features, self.edge_idx.to(device), self.edge_type.to(device))\n",
    "                node_embd, rel_embd = self.conv2(node_embd,self.edge_idx.to(device), self.edge_type.to(device), rel_embd)\n",
    "            else:\n",
    "                node_embd, rel_embd = self.conv1(node_embeding,self.edge_idx.to(device), self.edge_type.to(device), rel_embeding)\n",
    "                node_embd, rel_embd = self.conv2(node_embd,self.edge_idx.to(device), self.edge_type.to(device), rel_embd)\n",
    "            #print(node_embd.shape, rel_embd.shape)\n",
    "            return node_embd, rel_embd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:02.5855Z",
     "iopub.status.busy": "2022-05-01T03:47:02.583188Z",
     "iopub.status.idle": "2022-05-01T03:47:02.607726Z",
     "shell.execute_reply": "2022-05-01T03:47:02.607082Z",
     "shell.execute_reply.started": "2022-05-01T03:47:02.585456Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.rand(size = (8,20))\n",
    "b = torch.rand(size = (8,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:02.76306Z",
     "iopub.status.busy": "2022-05-01T03:47:02.760612Z",
     "iopub.status.idle": "2022-05-01T03:47:02.785178Z",
     "shell.execute_reply": "2022-05-01T03:47:02.784577Z",
     "shell.execute_reply.started": "2022-05-01T03:47:02.763017Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cat([a,b], axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:02.941679Z",
     "iopub.status.busy": "2022-05-01T03:47:02.941285Z",
     "iopub.status.idle": "2022-05-01T03:47:02.958129Z",
     "shell.execute_reply": "2022-05-01T03:47:02.957436Z",
     "shell.execute_reply.started": "2022-05-01T03:47:02.941645Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompGcn_with_temporal(nn.Module):\n",
    "    def __init__(self, conv_dim, num_layer ,num_relation, num_entity,node_dim, num_basis_vector, edge_idx, edge_type,model,num_class, score_func=\"TransE\"):\n",
    "        '''\n",
    "        Notice that in preprocessing, we assume that the node number will not be changed on the graph, only change relation.\n",
    "        input params:\n",
    "            1. conv_dim, (in_channel, out_channel)\n",
    "            2. num_layer, number of CompGCN layer, now assume to 2 per graph\n",
    "            3. num_relation, the number of relations_type for each graph(after preprocessing, should be the same for each graph)\n",
    "            4. num_entity, number of entity, should be the same for each graph\n",
    "            5. node_dimension, dimension of nodes\n",
    "            6. num_basis_vector, the first layer basis of first graph.\n",
    "            7. edge_idx, a list of edge_idx\n",
    "            8. edge_type, a list of edge_type\n",
    "            9. whole, use subgraph or whole graph\n",
    "            10. num_graphs, how many graphs will be used\n",
    "            11. model: Bert model extract text info\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.node_features = get_param(shape= (num_entity,node_dim))\n",
    "        # Bert model\n",
    "        self.model = model\n",
    "        assert node_dim == conv_dim[0]\n",
    "        self.conv1 = CompGcn_total(conv_dim[0], conv_dim[1], num_relation, num_basis_vector, edge_idx[0],edge_type[0],True)\n",
    "        self.conv2 = CompGcn_total(conv_dim[1], conv_dim[1], num_relation, num_basis_vector, edge_idx[1],edge_type[1],False)\n",
    "        self.conv3 = CompGcn_total(conv_dim[1], conv_dim[1], num_relation, num_basis_vector, edge_idx[2],edge_type[2],False)\n",
    "        # change bert input to same as before\n",
    "        self.ln1 = nn.Linear(768 + conv_dim[1], num_class)\n",
    "        self.drop_bert = nn.Dropout(0.2)\n",
    "        self.dropout_node = nn.Dropout(0.2)\n",
    "        self.score            = score_func\n",
    "        self.dropout_rel = nn.Dropout(0.4)\n",
    "        self.ln1 = self.func_init(self.ln1)\n",
    "    def func_init(self,m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        return m\n",
    "    def forward(self, input_ids,segment_ids, attention_mask  ,head_index, tail_index, rel_index):\n",
    "        '''\n",
    "        Node index and rel index are corresponding information in a batch for bert part, we only care about the node, edge relation in a batch.\n",
    "        Since the embedding is tail - relation to head, the source will be tail, target will be head\n",
    "        '''\n",
    "        with amp.autocast():\n",
    "            device = self.node_features.device\n",
    "            bert_out = self.model(input_ids = input_ids, attention_mask = attention_mask, token_type_ids = segment_ids)[\"pooler_output\"]\n",
    "            bert_out = self.drop_bert(bert_out)\n",
    "            node_embd1, rel_embd1 = self.conv1(self.node_features,device = device ) \n",
    "            node_embd2, rel_embd2 = self.conv2(node_embeding = node_embd1, rel_embeding = rel_embd1,device = device)\n",
    "            node_embd3, rel_embd3 = self.conv3(node_embeding = node_embd2, rel_embeding = rel_embd2,device = device)\n",
    "            # then choose corresponding index out:\n",
    "            # shape should be (len(index), hidden_out)\n",
    "            hidden_node_state = self.dropout_node(node_embd3[tail_index,:])\n",
    "            hidden_rel_state  = self.dropout_rel(rel_embd3[rel_index,:])\n",
    "            hidden_target_state = self.dropout_node(node_embd3[head_index,:])\n",
    "\n",
    "            # Don't need to divide into head, relation, tail, Here I use concatenation or summation\n",
    "            head, rel, tail      = (\n",
    "                                        hidden_node_state, \n",
    "                                        hidden_rel_state, \n",
    "                                        hidden_target_state\n",
    "                                   )\n",
    "            score                = Score_func(head, rel, tail, func_type=self.score)\n",
    "            score                = score.forward_score()\n",
    "            score = torch.cat([score, bert_out], axis = 1)\n",
    "            score = self.ln1(score)\n",
    "        return score # hidden_node_state, hidden_rel_state, hidden_target_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:03.127125Z",
     "iopub.status.busy": "2022-05-01T03:47:03.126529Z",
     "iopub.status.idle": "2022-05-01T03:47:03.153125Z",
     "shell.execute_reply": "2022-05-01T03:47:03.152273Z",
     "shell.execute_reply.started": "2022-05-01T03:47:03.127088Z"
    }
   },
   "outputs": [],
   "source": [
    "class Score_func(nn.Module):\n",
    "    \"\"\"\n",
    "        Func:\n",
    "            Contain all the score functions we often meet. Now we finished ConvE, TransE, TransH, DisMult\n",
    "        \n",
    "        Args:\n",
    "            sub_emb: the head embedding (subject)\n",
    "            rel_emb: the relation embedding (relation)\n",
    "            obj_emb: the tail embedding (object)\n",
    "            kernel_size: a tuple. Only when the score function is ConvE, we need it to do the \n",
    "                        convolutional computation. i.e. kernel_size = (hight, width)\n",
    "            func_type: a string indicating the score function we wanna use. default to be \"TransE\"\n",
    "            conv_drop: a list containing floats, indicating the dropout rate we will use in the ConvE. \n",
    "                        If None, set to be all the same as \"dropout\" value. Default to all be the \n",
    "                        tuned parameter in compGCN paper.\n",
    "            conv_bias: whether to use bias. Default to be True\n",
    "            gamma: a float - margin hyperparameter. Only when we use TransE as our score function, we \n",
    "                    need it. Default to be 40.0, the tuned best parameter in compGCN.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sub_emb, rel_emb, obj_emb, func_type=\"transE\", \n",
    "                 kernel_size = None, conv_drop=(0.2, 0.3, 0.2), \n",
    "                 conv_bias=True, gamma=40.0):\n",
    "        # we can't use self.__class__, because it may cause a recursive problem\n",
    "        super(Score_func, self).__init__()\n",
    "        \n",
    "        self.func_type = func_type.lower()\n",
    "        self.gamma     = gamma\n",
    "        self.sub_emb   = sub_emb\n",
    "        self.rel_emb   = rel_emb\n",
    "        self.obj_emb   = obj_emb\n",
    "        \n",
    "        if self.func_type == \"transh\":\n",
    "            self.relation_norm_embedding  = torch.nn.Embedding(num_embeddings=relation_num,\n",
    "                                                              embedding_dim=self.dimension)\n",
    "            self.relation_hyper_embedding = torch.nn.Embedding(num_embeddings=relation_num,\n",
    "                                                               embedding_dim=self.dimension)\n",
    "            self.entity_embedding         = torch.nn.Embedding(num_embeddings=entity_num,\n",
    "                                                               embedding_dim=self.dimension)\n",
    "        \n",
    "        if self.func_type == \"conve\":\n",
    "            assert not kernel_size is None  # to ensure that the kernel size is defined\n",
    "            \n",
    "            if not conv_drop:\n",
    "                self.hidden_drop = [dropout, dropout, dropout]\n",
    "            else:\n",
    "                l = len(hidden_drop)\n",
    "                assert l <= 3  # ensure the length of hidden_drop smaller equal to 3\n",
    "                if l == 1:\n",
    "                    self.conv_drop = [conv_drop[0], conv_drop[0], conv_drop[0]]\n",
    "                elif l == 2:\n",
    "                    self.conv_drop = [conv_drop[0], conv_drop[0], conv_drop[1]]\n",
    "                else:\n",
    "                    self.conv_drop = conv_drop\n",
    "                \n",
    "            \n",
    "            self.kernel_size    = kernel_size\n",
    "            self.bias           = conv_bias\n",
    "            \n",
    "            self.bn0            = torch.nn.BatchNorm2d(1)\n",
    "            self.bn1            = torch.nn.BatchNorm2d(self.out_channels)\n",
    "            self.bn2            = torch.nn.BatchNorm1d(self.kernel_size)\n",
    "\n",
    "            self.hidden_drop    = torch.nn.Dropout(self.conv_drop[0])\n",
    "            self.hidden_drop2   = torch.nn.Dropout(self.conv_drop[1])\n",
    "            self.feature_drop   = torch.nn.Dropout(self.conv_drop[2])\n",
    "            self.m_conv1        = torch.nn.Conv2d(1, out_channels=self.out_channels, \n",
    "                                                  kernel_size=(self.kernel_size, self.kernel_size), \n",
    "                                                  stride=1, padding=0, bias=self.bias)\n",
    "\n",
    "            flat_sz_h           = int(2*self.kernel_size[1]) - self.kernel_size + 1\n",
    "            flat_sz_w           = self.kernel_size[0] - self.kernel_size + 1\n",
    "            self.flat_sz        = flat_sz_h * flat_sz_w * self.out_channels\n",
    "            self.fc             = torch.nn.Linear(self.flat_sz, self.kernel_size)\n",
    "    \n",
    "    def concat(self, e1_embed, rel_embed):\n",
    "        e1_embed    = e1_embed. view(-1, 1, self.p.embed_dim)\n",
    "        rel_embed   = rel_embed.view(-1, 1, self.p.embed_dim)\n",
    "        stack_inp   = torch.cat([e1_embed, rel_embed], 1)\n",
    "        stack_inp   = torch.transpose(stack_inp, 2, 1).reshape((-1, 1, 2*self.p.k_w, self.p.k_h))\n",
    "        return stack_inp\n",
    "    \n",
    "    def projected(self, ent, norm):\n",
    "        norm = F.normalize(norm, p=2, dim=-1)\n",
    "        return ent - torch.sum(ent * norm, dim = 1, keepdim=True) * norm\n",
    "    \n",
    "    def forward_score(self):\n",
    "        with amp.autocast():\n",
    "            if   self.func_type == \"transe\":\n",
    "                x        = self.sub_emb + self.rel_emb - self.obj_emb\n",
    "            elif self.func_type == \"transh\":\n",
    "                head       = self.entity_embedding(self.sub_emb)\n",
    "                tail       = self.entity_embedding(self.obj_emb)\n",
    "                r_norm     = self.relation_norm_embedding(self.rel_emb)\n",
    "                r_hyper    = self.relation_hyper_embedding(self.rel_emb)\n",
    "                head_hyper = self.projected(head, r_norm)\n",
    "                tail_hyper = self.projected(tail, r_norm)\n",
    "                x          = torch.norm(head_hyper + r_hyper - tail_hyper, p=2, dim=2)\n",
    "            elif self.func_type == \"distmult\":\n",
    "                x        =   torch.mm(self.sub_emb + self.rel_emb, self.obj_emb.transpose(1, 0))\n",
    "                x        +=  self.bias.expand_as(x)\n",
    "            elif self.func_type == \"conve\":\n",
    "                stk_inp  = self.concat(sub_emb, rel_emb)\n",
    "                x        = self.bn0(stk_inp)\n",
    "                x        = self.m_conv1(x)\n",
    "                x        = self.bn1(x)\n",
    "                x        = F.relu(x)\n",
    "                x        = self.feature_drop(x)\n",
    "                x        = x.view(-1, self.flat_sz)\n",
    "                x        = self.fc(x)\n",
    "                x        = self.hidden_drop2(x)\n",
    "                x        = self.bn2(x)\n",
    "                x        = F.relu(x)\n",
    "\n",
    "                x = torch.mm(x, self.obj_emb.transpose(1,0))\n",
    "                x += self.bias.expand_as(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:03.311204Z",
     "iopub.status.busy": "2022-05-01T03:47:03.310387Z",
     "iopub.status.idle": "2022-05-01T03:47:03.31492Z",
     "shell.execute_reply": "2022-05-01T03:47:03.314187Z",
     "shell.execute_reply.started": "2022-05-01T03:47:03.311155Z"
    }
   },
   "outputs": [],
   "source": [
    "# test = ('de/Franz_Tobisch',\n",
    "#  'Prabhas',\n",
    "#  'Igor_Strelbin',\n",
    "#  'Quentin_N._Burdick',\n",
    "#  'Bamir_Topi',\n",
    "#  'Federal_University_of_Amazonas',\n",
    "#  'Emmanuel_Baffour',\n",
    "#  'R.E.M.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现两种结合方法\n",
    "1. 不用子图，对整张图补零，然后再和语义信息结合之前选择导出对应的index，这样子开销会很大，不一定能够支持训练。\n",
    "2. 用子图，对子图补零，这样不会出现计算不了的问题，而且由于CompGCN 其可学习参数为 relation basis，relation embedding， node feature embd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SubGraph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:04.020838Z",
     "iopub.status.busy": "2022-05-01T03:47:04.020265Z",
     "iopub.status.idle": "2022-05-01T03:47:04.024397Z",
     "shell.execute_reply": "2022-05-01T03:47:04.023738Z",
     "shell.execute_reply.started": "2022-05-01T03:47:04.020799Z"
    }
   },
   "outputs": [],
   "source": [
    "# class CompGcn_subgraph(nn.Module):\n",
    "#     def __init__(self, num_entity,node_dim ):\n",
    "#         '''\n",
    "#         In a subgraph, we first need to choose the index, take all the index containing in it out:\n",
    "       \n",
    "#         '''\n",
    "#         super().__init__()\n",
    "#         self.node_features_whole = get_param(shape = (num_entity, node_dim))\n",
    "#     def select_index(self,input_):\n",
    "#         '''\n",
    "#         这个函数需要通过给定的input string，去找出整图中对应的edge_idx 和 edge_type(当然可以在外面做)， 然后根据对应的edge idx 的value 去原始的Node_features 里去找\n",
    "#         对应的子图的node feature，其维度应该为(num_nodes_sub, node_dim), 对于relation，则不需要改动，仍用整张图即可\n",
    "#         '''\n",
    "#         raise NotImplementedError\n",
    "#     def forward(self, input_):\n",
    "#         batch_node_feature, batch_edge_idx, batch_edge_type = self.select_index(*input_)\n",
    "#         return batch_node_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:04.290024Z",
     "iopub.status.busy": "2022-05-01T03:47:04.289577Z",
     "iopub.status.idle": "2022-05-01T03:47:04.297338Z",
     "shell.execute_reply": "2022-05-01T03:47:04.296538Z",
     "shell.execute_reply.started": "2022-05-01T03:47:04.289988Z"
    }
   },
   "outputs": [],
   "source": [
    "# class CompGcn_subgraph_temporal(CompGcn_subgraph):\n",
    "#     def __init__(self, conv_dim,num_relation,node_dim, num_basis_vector, edge_idx, edge_type):\n",
    "#         '''\n",
    "#         1. conv_dim: (in_channel, out_channel)\n",
    "#         2. num_relation: number of relation for whole graph\n",
    "#         4. node_dim: dimension for each node\n",
    "#         5. basis_vector\n",
    "#         6. a list of edge_idx for sub_graph\n",
    "#         6. a list of edge_type for sub_graph\n",
    "#         '''\n",
    "#         super().__init__(num_entity, node_dim)\n",
    "#         self.conv1 = CompGcn_total(conv_dim[0], conv_dim[1], num_relation, num_basis_vector, edge_idx[0],edge_type[0],True)\n",
    "#         self.conv2 = CompGcn_total(conv_dim[0], conv_dim[1], num_relation, num_basis_vector, edge_idx[1],edge_type[1],False)\n",
    "#         self.conv3 = CompGcn_total(conv_dim[0], conv_dim[1], num_relation, num_basis_vector, edge_idx[2],edge_type[2],False)\n",
    "#         self.RNN_nodes = nn.RNN(input_size = conv_dim[0], hidden_size = conv_dim[1])\n",
    "#         self.RNN_relembd = nn.RNN(input_size = conv_dim[0], hidden_size = conv_dim[1])\n",
    "#         self.dropout_node = nn.Dropout(0.2)\n",
    "#         self.dropout_rel = nn.Dropout(0.4)\n",
    "#     def forward2(self, input_string):\n",
    "#         batch_node_features, head_index, rel_index, tail_index =self.forward(input_string)\n",
    "#         node_embd1, rel_embd1 = self.conv1(batch_node_features) \n",
    "#         node_embd2, rel_embd2 = self.conv2(node_embeding = node_embd1, rel_embeding = rel_embd1)\n",
    "#         node_embd3, rel_embd3 = self.conv3(node_embeding = node_embd2, rel_embeding = rel_embd2)\n",
    "#         hidden_node_state = self.dropout_node(self.RNN_nodes(torch.cat([node_embd1[tail_index,:].unsqueeze(0), node_embd2[tail_index,:].unsqueeze(0), node_embd3[tail_index,:].unsqueeze(0)]))[0])\n",
    "#         hidden_rel_state = self.dropout_rel(self.RNN_relembd(torch.cat([rel_embd1[rel_index,:].unsqueeze(0), rel_embd2[rel_index,:].unsqueeze(0),rel_embd3[rel_index,:].unsqueeze(0)]))[0])\n",
    "#         hidden_node_state = self.dropout_node(self.RNN_nodes(torch.cat([node_embd1[head_index,:].unsqueeze(0), node_embd2[head_index,:].unsqueeze(0), node_embd3[head_index,:].unsqueeze(0)]))[0])\n",
    "#         return hidden_node_state[-1,:,:].squeeze(0), hidden_rel_state[-1,:,:].squeeze(0), hidden_target_state[-1,:,:].squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and KG-Bert part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:04.815596Z",
     "iopub.status.busy": "2022-05-01T03:47:04.815281Z",
     "iopub.status.idle": "2022-05-01T03:47:04.827132Z",
     "shell.execute_reply": "2022-05-01T03:47:04.826083Z",
     "shell.execute_reply.started": "2022-05-01T03:47:04.815563Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_input(tokenizer, text1, text2=None, text3=None, labels = None,max_length=512):\n",
    "    '''\n",
    "    This function will change the given input from double to triple\n",
    "    '''\n",
    "    #do the basic tokenization without changing to index\n",
    "    tokens_1 = tokenizer.tokenize(text1)\n",
    "    if text2 is not None:\n",
    "        tokens_2 = tokenizer.tokenize(text2)\n",
    "    if text3 is not None:\n",
    "        tokens_3 = tokenizer.tokenize(text3)\n",
    "    #as shown in kg-bert, do the truncation\n",
    "    while True:\n",
    "        #do the trunctation \n",
    "        total_length = len(tokens_1)+len(tokens_2)+len(tokens_3)\n",
    "        if total_length<= max_length-4:\n",
    "            break\n",
    "        if len(tokens_1)>len(tokens_2) and len(tokens_1)>len(tokens_3):\n",
    "            tokens_1.pop()\n",
    "        elif len(tokens_2)>len(tokens_1) and len(tokens_2)>len(tokens_3):\n",
    "            tokens_2.pop()\n",
    "        elif len(tokens_3)>len(tokens_2) and len(tokens_3)>len(tokens_1):\n",
    "            tokens_3.pop()\n",
    "        else:\n",
    "            #else pop the token3(tail)\n",
    "            tokens_3.pop()\n",
    "    #segment encoding\n",
    "    final_token = [\"[CLS]\"]+tokens_1+[\"[SEP]\"]\n",
    "    #segment for first sentence\n",
    "    segment_ids = [0]*len(final_token)\n",
    "    if text2 is not None:\n",
    "        final_token+=tokens_2+[\"[SEP]\"]\n",
    "        segment_ids+=[1]*(len(tokens_2)+1)\n",
    "    if text3 is not None:\n",
    "        final_token+=tokens_3+[\"[SEP]\"]\n",
    "        segment_ids+=[0]*(len(tokens_3)+1)\n",
    "    #change it to the index\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(final_token)\n",
    "    #for padding\n",
    "    padding = [0]*(max_length - len(input_ids))\n",
    "    #for attention mask\n",
    "    attention_mask = [1]*len(input_ids)\n",
    "    input_ids+=padding\n",
    "    attention_mask+= padding\n",
    "    segment_ids+=padding\n",
    "    assert len(input_ids) == max_length\n",
    "    assert len(attention_mask) == max_length\n",
    "    assert len(segment_ids) == max_length\n",
    "    return {\"input_ids\": input_ids,\n",
    "            \"segment_ids\": segment_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\":labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:05.052522Z",
     "iopub.status.busy": "2022-05-01T03:47:05.05188Z",
     "iopub.status.idle": "2022-05-01T03:47:05.060123Z",
     "shell.execute_reply": "2022-05-01T03:47:05.058976Z",
     "shell.execute_reply.started": "2022-05-01T03:47:05.052484Z"
    }
   },
   "outputs": [],
   "source": [
    "class language_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        '''\n",
    "        df is dataframe given previously\n",
    "        '''\n",
    "        self.df = df\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        This function will return the index\n",
    "        '''\n",
    "        dic = change_input(self.tokenizer,self.df.iloc[idx][\"head\"], self.df.iloc[idx][\"relation\"], self.df.iloc[idx][\"tail\"],self.df.iloc[idx][\"labels\"])\n",
    "        return torch.tensor(dic[\"input_ids\"]), torch.tensor(dic[\"segment_ids\"]), torch.tensor(dic[\"attention_mask\"]), torch.tensor(dic[\"labels\"]), self.df.iloc[idx][\"index_where\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:05.283891Z",
     "iopub.status.busy": "2022-05-01T03:47:05.283248Z",
     "iopub.status.idle": "2022-05-01T03:47:05.291417Z",
     "shell.execute_reply": "2022-05-01T03:47:05.290653Z",
     "shell.execute_reply.started": "2022-05-01T03:47:05.283858Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_index(head, relation,tail,head2idx,rel2idx,edge_idx,edge_type):\n",
    "    '''\n",
    "    This function select the index given by correct index\n",
    "    '''\n",
    "    batch_head_tail_idx = [[head2idx[h], head2idx[t]] for h,t in zip(head, tail)]\n",
    "    rel_idx = [rel2idx[i] for i in relation]\n",
    "    ls = []\n",
    "    for i, j in zip(batch_head_tail_idx, rel_idx):\n",
    "        # column index\n",
    "        #print(np.argwhere(np.isin(edge_idx[0],i[0] )&np.isin(edge_idx[1], i[1])&np.isin(edge_type, j)))\n",
    "        ls.append(np.argwhere(np.isin(edge_idx[0],i[0] )&np.isin(edge_idx[1], i[1])&np.isin(edge_type, j))[0])          \n",
    "    idx = np.concatenate(ls)\n",
    "#     print(idx)\n",
    "    rel_value = edge_type[idx]\n",
    "    head_value, tail_value = edge_idx[:,idx]\n",
    "    assert len(head_value) == len(tail_value) == len(rel_value)\n",
    "    return head_value.tolist(), tail_value.tolist(), rel_value.tolist()\n",
    "# head_idx, tail_idx, rel_idx = select_index(head, relation,tail, head2idx, rel2idx,edge_idx_3, edge_type_2)\n",
    "# hidden_node, hidden_rel, hidden_target = tmp(input_ids, seg_ids, att_mask,head_idx,tail_idx, rel_idx)\n",
    "# hidden_node.shape, hidden_rel.shape, hidden_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:05.568902Z",
     "iopub.status.busy": "2022-05-01T03:47:05.568378Z",
     "iopub.status.idle": "2022-05-01T03:47:05.574714Z",
     "shell.execute_reply": "2022-05-01T03:47:05.574008Z",
     "shell.execute_reply.started": "2022-05-01T03:47:05.568865Z"
    }
   },
   "outputs": [],
   "source": [
    "# def train_with_amp(net, train_set, criterion, optimizer, epochs,batch_size, scheduler, gradient_accumulate_step, max_grad_norm ,device):\n",
    "#     net.train()\n",
    "#     # instantiate a scalar object  \n",
    "#     print(\"train on \" + str(device))\n",
    "#     enable_amp = True if \"cuda\" in device.type else False\n",
    "#     scaler = amp.GradScaler(enabled= enable_amp)\n",
    "#     net.to(device)\n",
    "#     global_step = 0\n",
    "#     train_iter = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
    "#     for epoch in range(epochs):\n",
    "#         for idx, value in enumerate(train_iter):\n",
    "#             input_ids, seg_ids, att_mask, labels, index = value\n",
    "#             input_ids = input_ids.to(device)\n",
    "#             att_mask =att_mask.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             seg_ids = seg_ids.to(device)\n",
    "#             head_values = torch.tensor(index[0]).to(device)\n",
    "#             tail_values = torch.tensor(index[2]).to(device)\n",
    "#             rel_values = torch.tensor(index[1]).to(device)\n",
    "#             # when forward process, use amp\n",
    "#             with amp.autocast(enabled= enable_amp):\n",
    "#                 output = net(input_ids, seg_ids, att_mask,head_values,tail_values, rel_values)  \n",
    "#             loss = criterion(output, labels.view(-1,1).float())\n",
    "#             # prevent gradient to 0\n",
    "#             if gradient_accumulate_step > 1:\n",
    "#                 # 如果显存不足，通过 gradient_accumulate 来解决\n",
    "#                 loss = loss/gradient_accumulate_step\n",
    "            \n",
    "#             # 放大梯度，避免其消失\n",
    "#             scaler.scale(loss).backward()\n",
    "#             # do the gradient clip\n",
    "#             gradient_norm = nn.utils.clip_grad_norm_(net.parameters(),max_grad_norm)\n",
    "#             if (idx + 1) % gradient_accumulate_step == 0:\n",
    "#                 # 多少 step 更新一次梯度\n",
    "#                 # 通过 scaler.step 来unscale 回梯度值， 如果气结果不是infs 和Nans， 调用optimizer.step()来更新权重\n",
    "#                 # 否则忽略step调用， 保证权重不更新\n",
    "#                 scaler.step(optimizer)\n",
    "#                 scaler.update()\n",
    "#                 optimizer.zero_grad()\n",
    "#                 global_step += 1\n",
    "#                 scheduler.step()\n",
    "#             # 每100次计算 print 出一次loss\n",
    "#             if idx % 1000 == 0 or idx == len(train_iter) -1:\n",
    "#                 with torch.no_grad():\n",
    "#                     print(\"==============Epochs \"+ str(epoch) + \" ======================\")\n",
    "#                     print(\"loss: \" + str(loss) + \"; grad_norm: \" + str(gradient_norm))\n",
    "#                 torch.save({'epoch': epoch,\n",
    "#                 'model_state_dict': net.state_dict(),\n",
    "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                 'loss': loss},\"./checkpoint.params\")\n",
    "#             print(\"successfully done one train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:47:05.956802Z",
     "iopub.status.busy": "2022-05-01T03:47:05.956273Z",
     "iopub.status.idle": "2022-05-01T03:47:05.974413Z",
     "shell.execute_reply": "2022-05-01T03:47:05.973659Z",
     "shell.execute_reply.started": "2022-05-01T03:47:05.956741Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "# In[ ]:\n",
    "def train_with_amp(net, train_set, criterion, optimizer, epochs,batch_size, scheduler, gradient_accumulate_step, max_grad_norm , num_gpu):\n",
    "    net.train()   \n",
    "    \n",
    "    # instantiate a scalar object \n",
    "    ls          = []\n",
    "    device_ids  = [try_gpu(i) for i in range(num_gpu)]\n",
    "    device  = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    print(\"\\ntrain on %s\\n\"%str(device_ids))\n",
    "    enable_amp  = True if \"cuda\" in device_ids[0].type else False\n",
    "    scaler      = amp.GradScaler(enabled= enable_amp)\n",
    "    net         = nn.DataParallel(net, device_ids = device_ids)\n",
    "    net.to(device)\n",
    "    train_iter  = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        for idx, value in enumerate(train_iter):\n",
    "            ini_time    = time.time()\n",
    "            input_ids, seg_ids, att_mask, labels, index = value\n",
    "            input_ids   = input_ids.to(device_ids[0])\n",
    "            att_mask    = att_mask.to(device_ids[0])\n",
    "            labels      = labels.to(device_ids[0])\n",
    "            seg_ids     = seg_ids.to(device_ids[0])\n",
    "            head_values = torch.tensor(index[0]).to(device_ids[0])\n",
    "            tail_values = torch.tensor(index[2]).to(device_ids[0])\n",
    "            rel_values  = torch.tensor(index[1]).to(device_ids[0])\n",
    "            # when forward process, use amp\n",
    "            with amp.autocast(enabled= enable_amp):\n",
    "                output  = net(input_ids, seg_ids, att_mask,head_values,tail_values, rel_values)  \n",
    "            loss        = criterion(output, labels.view(-1,1).float())\n",
    "            # prevent gradient to 0\n",
    "            if gradient_accumulate_step > 1:\n",
    "                # 如果显存不足，通过 gradient_accumulate 来解决\n",
    "                loss    = loss/gradient_accumulate_step\n",
    "            \n",
    "            # 放大梯度，避免其消失\n",
    "            scaler.scale(loss).mean().backward()\n",
    "            # do the gradient clip\n",
    "            gradient_norm = nn.utils.clip_grad_norm_(net.parameters(),max_grad_norm)\n",
    "            if (idx + 1) % gradient_accumulate_step == 0:\n",
    "                # 多少 step 更新一次梯度\n",
    "                # 通过 scaler.step 来unscale 回梯度值， 如果气结果不是infs 和Nans， 调用optimizer.step()来更新权重\n",
    "                # 否则忽略step调用， 保证权重不更新\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "                print(\"train 1 times\")\n",
    "            # 每1000次计算 print 出一次loss\n",
    "            if idx % 1000 == 0 or idx == len(train_iter) -1:\n",
    "                with torch.no_grad():\n",
    "                    print(\"==============Epochs \"+ str(epoch) + \" ======================\")\n",
    "                    print(\"loss: \" + str(loss) + \"; grad_norm: \" + str(gradient_norm))\n",
    "                ls.append(loss.item())\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': net.state_dict(),\n",
    "                    'param_groups': optimizer.state_dict()[\"param_groups\"],\n",
    "                    'loss': ls\n",
    "                },\"./checkpoint.params\")\n",
    "            with open(\"train_log\", \"a\") as f:\n",
    "                f.write(\"Epoch %s, Batch %s: %.4f sec\\n\"%(epoch, idx, time.time() - ini_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-01T03:48:47.400945Z",
     "iopub.status.busy": "2022-05-01T03:48:47.400387Z",
     "iopub.status.idle": "2022-05-01T03:50:30.263526Z",
     "shell.execute_reply": "2022-05-01T03:50:30.262479Z",
     "shell.execute_reply.started": "2022-05-01T03:48:47.400893Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    edge_idx_1 = torch.tensor(np.load(\"../input/3-graphs-info/edge_idx0.npz\")[\"arr_0\"])\n",
    "    edge_idx_2 = torch.tensor(np.load(\"../input/3-graphs-info/edge_idx1.npz\")[\"arr_0\"])\n",
    "    edge_idx_3 = torch.tensor(np.load(\"../input/3-graphs-info/edge_idx2.npz\")[\"arr_0\"])\n",
    "    num_nodes_0 = torch.tensor(np.load(\"../input/3-graphs-info/graph_0_num_nodes.npz\")[\"arr_0\"])\n",
    "    num_nodes_1 = torch.tensor(np.load(\"../input/3-graphs-info/graph_1_num_nodes.npz\")[\"arr_0\"])\n",
    "    num_nodes_2 = torch.tensor(np.load(\"../input/3-graphs-info/graph_2_num_nodes.npz\")[\"arr_0\"])\n",
    "    num_relation_0 = torch.tensor(np.load(\"../input/3-graphs-info/graph_0_num_edges.npz\")[\"arr_0\"])\n",
    "    num_relation_1 = torch.tensor(np.load(\"../input/3-graphs-info/graph_1_num_edges.npz\")[\"arr_0\"])\n",
    "    num_relation_2 = torch.tensor(np.load(\"../input/3-graphs-info/graph_2_num_edges.npz\")[\"arr_0\"])\n",
    "    edge_type_0 = torch.tensor(np.load(\"../input/3-graphs-info/edge_type0.npz\")[\"arr_0\"])\n",
    "    edge_type_1 = torch.tensor(np.load(\"../input/3-graphs-info/edge_type1.npz\")[\"arr_0\"])\n",
    "    edge_type_2 = torch.tensor(np.load(\"../input/3-graphs-info/edge_type2.npz\")[\"arr_0\"])\n",
    "    head2idx = np.load('../input/3-graphs-info/graph_2entity2index.npy', allow_pickle=True).item()\n",
    "    rel2idx =  np.load('../input/3-graphs-info/graph_2rel2index.npy', allow_pickle=True).item()\n",
    "    train = pd.read_csv(\"../input/train-valid-test-dataset/train.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
    "    train[\"index_where\"] = train[\"index_where\"].apply(ast.literal_eval)\n",
    "    train_set = language_Dataset(train)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    conv_dim, num_layer, node_dim, num_basis, edge_idx, edge_type = [10, 20], 2, 10, 37, [edge_idx_1,edge_idx_2,edge_idx_3],[edge_type_0,edge_type_1,edge_type_2]\n",
    "    tmp = CompGcn_with_temporal(conv_dim,num_layer, num_relation_2, num_nodes_2+1, node_dim, num_basis,edge_idx, edge_type, model,1)\n",
    "    batch_size = 2\n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(tmp.parameters(), lr = 2e-4)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer= optimizer, num_warmup_steps = 0, num_training_steps= len(torch.utils.data.DataLoader(train_set, batch_size = batch_size)), num_cycles = 0.5)\n",
    "    train_with_amp(tmp, train_set, loss,optimizer,1,2, scheduler,1,1000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-01T03:35:56.86594Z",
     "iopub.status.idle": "2022-05-01T03:35:56.866341Z",
     "shell.execute_reply": "2022-05-01T03:35:56.866149Z",
     "shell.execute_reply.started": "2022-05-01T03:35:56.866119Z"
    }
   },
   "outputs": [],
   "source": [
    "# def train(net, training_dataset, testing_dataset = None, lr = 0.01, loss_func=nn.CrossEntropyLoss ,\n",
    "#           num_epoches = 30, batch_size = 2, finetuning=False, plot=False):\n",
    "#     \"\"\"\n",
    "#         Func:\n",
    "#             To train the model\n",
    "        \n",
    "#         Args:\n",
    "#             net: the neuronal network\n",
    "#             training_dataset: a tensor form of dataset\n",
    "#             testing_dataset: a tensor form of dataset\n",
    "#             lr: learning rate\n",
    "#             loss_func: a callable loss function defined in torch.nn (for example, nn.CrossEntropyLoss())\n",
    "#             num_epoches: the number of epoches\n",
    "#             batch_size: the size of a batch\n",
    "#             finetuning: whether we need to initialize the weights. If true, pass a list \n",
    "#                         to indicate some specific layers, so that we can keep the weights fixed \n",
    "#                         within the specified layers (include the start and ending layer). For\n",
    "#                         example, [2, 4] means keep 2 to 4 layers fixed: [start_layer, end_layer].\n",
    "#                         We count layers begin from 0. Default to be False(initialize for every layer).\n",
    "#                         If it's True, we just use the pre-trained weights, and continue to train the \n",
    "#                         model.\n",
    "#     \"\"\"\n",
    "#     # to ensure we have a loss function\n",
    "#     assert loss_func != None, \"Must pass a loss function\"\n",
    "    \n",
    "#     device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#     print(\"Training on \", device)\n",
    "    \n",
    "#     # move all the tensor to GPU\n",
    "#     def init_weights(m):\n",
    "#         if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "#             nn.init.xavier_uniform_(m.weight)#初始化\n",
    "#     if not finetuning and not type(finetuning) == list:\n",
    "#         net.apply(init_weights)#将其应用在每层网络\n",
    "#     elif type(finetuning) == list:\n",
    "#         # ensure the number is positive\n",
    "#         for i in range(len(finetuning)):\n",
    "#             if finetuning[i] < 0:\n",
    "#                 finetuning[i] += len(list(net.children()))\n",
    "#         if finetuning[0] > finetuning[1]:\n",
    "#             finetuning[0], finetuning[1] = finetuning[1], finetuning[0]\n",
    "#         count = 0\n",
    "#         para_optim = []\n",
    "#         for k in net.children():\n",
    "#             count += 1\n",
    "#             # finetuning layers should be changed properly\n",
    "#             if count > finetuning[1]:\n",
    "#                 for param in k.parameters():\n",
    "#                     para_optim.append(param)\n",
    "#             elif count < finetuning[0]:\n",
    "#                 for param in k.parameters():\n",
    "#                     para_optim.append(param)\n",
    "#             else:\n",
    "#                 for param in k.parameters():\n",
    "#                     param.requires_grad = False\n",
    "#     net.to(device)\n",
    "    \n",
    "#     training_iter = torch.utils.data.DataLoader(training_dataset, batch_size = batch_size, shuffle =True)\n",
    "#     if testing_dataset is not None:\n",
    "#         testing_iter = torch.utils.data.DataLoader(testing_dataset, shuffle = False, batch_size = batch_size)\n",
    "    \n",
    "#     # config the optimizer and the loss function\n",
    "#     # ------------------------------------------------   Change the optimizer here -------------------------------------------------- #\n",
    "#     optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr = lr)\n",
    "#     # ------------------------------------------------------------------------------------------------------------------------------- #\n",
    "    \n",
    "#     loss = loss_func\n",
    "#     if plot:\n",
    "#         animator = d2l.Animator(xlabel = \"epoch\", xlim=[1,num_epoches], legend=[\"train_loss\",\"train_Acc\", \"test_acc\"])\n",
    "#     num_batches = len(training_iter)\n",
    "\n",
    "#     # plot the loss dynamically\n",
    "#     train_loss = []\n",
    "#     train_acc = []\n",
    "#     net.train()    # turn on the training model\n",
    "    \n",
    "#     for epoch in range(num_epoches):\n",
    "#         # save a model every 2 epoches\n",
    "#         torch.save(model, \"./model_v01_epoch(%s).pt\"%(epoch+1))\n",
    "#         metric = d2l.Accumulator(3)\n",
    "#         # for every step\n",
    "#         for i,value in enumerate(training_iter):\n",
    "#             optimizer.zero_grad()\n",
    "#         # ------------------------------------------------   Change the training input here -------------------------------------------------- #\n",
    "#             input_ids, seg_ids, att_mask, labels, head, tail = value\n",
    "#             head_values, tail_values, rel_values = select_index(head, tail, head2idx, edge_idx_3, edge_type_2)\n",
    "#             input_ids = input_ids.to(device).long()\n",
    "#             att_mask =att_mask.to(device).long()\n",
    "#             labels = labels.to(device).long()\n",
    "#             seg_ids = seg_ids.to(device).long()\n",
    "#             output = net(input_ids, seg_ids, att_mask,head_values,tail_values, rel_values)\n",
    "#             print(output.shape)\n",
    "#         # ------------------------------------------------------------------------------------------------------------------------------------ #\n",
    "#             l = loss(output.float(), labels[0].long())\n",
    "#             l.backward()\n",
    "#             optimizer.step()\n",
    "#             with torch.no_grad():\n",
    "#                 metric.add(l * input_ids.shape[0], d2l.accuracy(output,labels), input_ids.shape[0])\n",
    "#                 train_loss.append(metric[0]/metric[2])\n",
    "#                 train_acc.append( metric[1]/metric[2])\n",
    "# #                 train_loss = metric[0]/metric[2]\n",
    "# #                 train_acc  = metric[1]/metric[2]\n",
    "# #                 if (i+1) % (num_batches//5) ==0 or i == num_batches-1:\n",
    "# #                     animator.add(epoch+(i+1)/num_batches, (train_loss,train_acc, None))\n",
    "#             #print(\"successfully train for period \",i)\n",
    "#             if plot and i % 1000 == 0:\n",
    "#                 with torch.no_grad():\n",
    "#                     dic = {\"epoch\":epoch,\"iteration\":i,\"optimizer\":optimizer.state_dict(),\"net\":net.state_dict()}\n",
    "#                     torch.save(dic,\"./model_params\")\n",
    "#                     plt.figure()\n",
    "#                     x_ = range(len(train_loss))\n",
    "#                     plt.plot(x_,train_loss,color=\"yellow\")\n",
    "#                     plt.plot(x_, train_acc,color = \"red\")\n",
    "#         if testing_dataset is not None:\n",
    "#             test_acc = evaluate_accuracy(net, graph_info, testing_iter)\n",
    "#             if plot:\n",
    "#                 animator.add(epoch+1,(None,None,test_acc))\n",
    "#         print(\"epoch %d, loss: %f\"%(epoch, train_loss[-1]))\n",
    "    \n",
    "#     return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-01T03:35:56.86758Z",
     "iopub.status.idle": "2022-05-01T03:35:56.868024Z",
     "shell.execute_reply": "2022-05-01T03:35:56.867824Z",
     "shell.execute_reply.started": "2022-05-01T03:35:56.867798Z"
    }
   },
   "outputs": [],
   "source": [
    "# from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-01T03:35:56.869478Z",
     "iopub.status.idle": "2022-05-01T03:35:56.869893Z",
     "shell.execute_reply": "2022-05-01T03:35:56.869698Z",
     "shell.execute_reply.started": "2022-05-01T03:35:56.869676Z"
    }
   },
   "outputs": [],
   "source": [
    "# train(net,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-01T03:35:56.871141Z",
     "iopub.status.idle": "2022-05-01T03:35:56.871531Z",
     "shell.execute_reply": "2022-05-01T03:35:56.87134Z",
     "shell.execute_reply.started": "2022-05-01T03:35:56.871318Z"
    }
   },
   "outputs": [],
   "source": [
    "# conv_dim, num_layer, node_dim, num_basis, edge_idx, edge_type = [10, 20], 2, 10, 38, [edge_idx_1,edge_idx_2,edge_idx_3],[edge_type_0,edge_type_1,edge_type_2]\n",
    "# net = CompGcn_with_temporal(conv_dim,num_layer, num_relation_2+1, num_nodes_2+1, node_dim, num_basis,edge_idx, edge_type, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
