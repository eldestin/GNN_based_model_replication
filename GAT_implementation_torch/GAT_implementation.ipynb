{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f09e7d",
   "metadata": {},
   "source": [
    "## 数据集的处理\n",
    "1. 首先标注数据(待定)\n",
    "2. 拿到对应的稀疏矩阵和label后，通过原始数据构建一个adj_list(GAT源码中用的是一个字典)\n",
    "3. 标准化\n",
    "4. 根据拿到的字典对edge进行统计,并构造edge矩阵shape=(2, num_edges)\n",
    "5. 划分数据集通过indices来构建(我们用的是自然语言)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82366cf8",
   "metadata": {},
   "source": [
    "## 一些知识图谱的定义\n",
    "1. rdfs:range 用来表示属性的取值类型\n",
    "2. rdfs:domain 用来表示属性的域，即属于哪个类别\n",
    "3. OWL web ontology language(声明性的，非编程语言，用逻辑的方式描述一个事物的状态)，有点类似于一种性质，比如owl:TransitiveProperty （腾讯总部， 位于， 深圳），(深圳， 位于， 广东)=> （腾讯总部， 位于， 广东）\n",
    "4. 如果不需要这些数据，如果对生成负类样本，就无法有足够好的负类样本了（比如里约热内卢替换为狗，都不是一个大类的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97f7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from d2l import torch as d2l\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b13eed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(size = (2,2,3))\n",
    "b = torch.rand(size = (1,2,3))\n",
    "(a*b).sum(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640f5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_fact = pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoDateFacts.tsv\", sep='\\t',header=None).drop(0,axis=1)\n",
    "fact = pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoFacts.tsv\", sep='\\t', header=None).drop(0,axis=1)\n",
    "literal_fact =  pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoLiteralFacts.tsv\", sep='\\t', header=None).drop(0,axis=1)\n",
    "#schema 是一个限制条件，限制你的头/尾的取值范围一类的\n",
    "schema =  pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoSchema.tsv\", sep='\\t', header=None).drop(4,axis=1)\n",
    "# taxonomy 代表其构建的方式以及对应的属性\n",
    "taxonomy =  pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoTaxonomy.tsv\", sep='\\t', header=None).drop(0,axis=1)\n",
    "# 大类\n",
    "types =  pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoTypes.tsv\", sep='\\t', header=None).drop(0,axis=1)\n",
    "# instanceof，也为属性\n",
    "wiki_ins =  pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoWikidataInstances.tsv\", sep='\\t', header=None).drop(0,axis=1)\n",
    "wiki_info_en =  pd.read_csv(\"D:/jupyter/kg-bert/sample/yagoWikipediaInfo_en.tsv\", sep='\\t', header=None).drop(0,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb61300",
   "metadata": {},
   "source": [
    "### 所以我们只需要: fact, wiki_info_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1fc19ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    temp = data[data[3].apply(lambda x: \"<\" in x)].copy()\n",
    "   # print(data)\n",
    "    for i in temp.columns:\n",
    "        data[i]=data[i].apply(lambda x: x.split(\"<\")[-1].split(\">\")[0])\n",
    "    data.iloc[:,-1] = data.iloc[:,-1].apply(lambda x: x.split(\"^^\")[0])\n",
    "    return data\n",
    "# date_fc = preprocessing(date_fact)\n",
    "fc = preprocessing(fact)\n",
    "# literal_fc = preprocessing(literal_fact)\n",
    "wiki_info_en_ = preprocessing(wiki_info_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.read_csv(\"F:/yago-3.0.2-native/yagoFacts.tsv\",header=None, sep = \"\\t\").drop(4,axis=1)[1:].reset_index().drop(\"index\",axis=1)\n",
    "# # b = pd.read_csv(\"F:/yago-3.0.2-native/yagoMetaFacts.tsv\",header =None, sep=\"\\t\")[1:].reset_index().drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21bf7385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;id_156a81d_z7a_1lfplq&gt;</td>\n",
       "      <td>&lt;Onchiam&gt;</td>\n",
       "      <td>&lt;isLocatedIn&gt;</td>\n",
       "      <td>&lt;Kerala&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;id_u0gksp_ab2_zz7558&gt;</td>\n",
       "      <td>&lt;Gregory_S._Martin&gt;</td>\n",
       "      <td>&lt;hasWonPrize&gt;</td>\n",
       "      <td>&lt;Order_of_the_Sword_(United_States)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;id_9taxo5_1ul_1oe1uea&gt;</td>\n",
       "      <td>&lt;Wouter_Vrancken&gt;</td>\n",
       "      <td>&lt;playsFor&gt;</td>\n",
       "      <td>&lt;K.V._Kortrijk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;id_gfqocs_dhj_27wsag&gt;</td>\n",
       "      <td>&lt;Anthony_Gilbert_(author)&gt;</td>\n",
       "      <td>&lt;diedIn&gt;</td>\n",
       "      <td>&lt;London&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;id_z13ez0_13l_1v6yd3x&gt;</td>\n",
       "      <td>&lt;Johan_Jacobsen&gt;</td>\n",
       "      <td>&lt;directed&gt;</td>\n",
       "      <td>&lt;The_Invisible_Army&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628161</th>\n",
       "      <td>&lt;id_2f9lh8_z7a_vipgwv&gt;</td>\n",
       "      <td>&lt;Sambaregou&gt;</td>\n",
       "      <td>&lt;isLocatedIn&gt;</td>\n",
       "      <td>&lt;Zabré_Department&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628162</th>\n",
       "      <td>&lt;id_u02dc9_14h_1hqlz5i&gt;</td>\n",
       "      <td>&lt;Miguel_Estanislao_Soler&gt;</td>\n",
       "      <td>&lt;isPoliticianOf&gt;</td>\n",
       "      <td>&lt;Buenos_Aires_Province&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628163</th>\n",
       "      <td>&lt;id_1m1a5xw_ice_2garf6&gt;</td>\n",
       "      <td>&lt;Orting,_Washington&gt;</td>\n",
       "      <td>&lt;hasWebsite&gt;</td>\n",
       "      <td>&lt;http://www.cityoforting.org&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628164</th>\n",
       "      <td>&lt;id_81fluf_1ul_1jmf8sk&gt;</td>\n",
       "      <td>&lt;Harvey_Esajas&gt;</td>\n",
       "      <td>&lt;playsFor&gt;</td>\n",
       "      <td>&lt;A.S.D._Legnano_Calcio_1913&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628165</th>\n",
       "      <td>&lt;id_1yrfk7p_z7a_k5iicw&gt;</td>\n",
       "      <td>&lt;NEMO_(museum)&gt;</td>\n",
       "      <td>&lt;isLocatedIn&gt;</td>\n",
       "      <td>&lt;Netherlands&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5628166 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                           1  \\\n",
       "0        <id_156a81d_z7a_1lfplq>                   <Onchiam>   \n",
       "1         <id_u0gksp_ab2_zz7558>         <Gregory_S._Martin>   \n",
       "2        <id_9taxo5_1ul_1oe1uea>           <Wouter_Vrancken>   \n",
       "3         <id_gfqocs_dhj_27wsag>  <Anthony_Gilbert_(author)>   \n",
       "4        <id_z13ez0_13l_1v6yd3x>            <Johan_Jacobsen>   \n",
       "...                          ...                         ...   \n",
       "5628161   <id_2f9lh8_z7a_vipgwv>                <Sambaregou>   \n",
       "5628162  <id_u02dc9_14h_1hqlz5i>   <Miguel_Estanislao_Soler>   \n",
       "5628163  <id_1m1a5xw_ice_2garf6>        <Orting,_Washington>   \n",
       "5628164  <id_81fluf_1ul_1jmf8sk>             <Harvey_Esajas>   \n",
       "5628165  <id_1yrfk7p_z7a_k5iicw>             <NEMO_(museum)>   \n",
       "\n",
       "                        2                                     3  \n",
       "0           <isLocatedIn>                              <Kerala>  \n",
       "1           <hasWonPrize>  <Order_of_the_Sword_(United_States)>  \n",
       "2              <playsFor>                       <K.V._Kortrijk>  \n",
       "3                <diedIn>                              <London>  \n",
       "4              <directed>                  <The_Invisible_Army>  \n",
       "...                   ...                                   ...  \n",
       "5628161     <isLocatedIn>                    <Zabré_Department>  \n",
       "5628162  <isPoliticianOf>               <Buenos_Aires_Province>  \n",
       "5628163      <hasWebsite>         <http://www.cityoforting.org>  \n",
       "5628164        <playsFor>          <A.S.D._Legnano_Calcio_1913>  \n",
       "5628165     <isLocatedIn>                         <Netherlands>  \n",
       "\n",
       "[5628166 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d02e2",
   "metadata": {},
   "source": [
    "## 构建adj_list\n",
    "即拿到dic的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "71c5873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ = pd.concat([fc,wiki_info_en_],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "314709fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj_ls(total_):\n",
    "    '''\n",
    "    input: total_, a DataFrame\n",
    "    '''\n",
    "    #创建索引和词语对应\n",
    "    head_tail = pd.unique(pd.concat([total_[1],total_[3]],ignore_index=True))\n",
    "    head_tail_index = range(len((head_tail)))\n",
    "    head2index = {}\n",
    "    for head,index in zip(head_tail,head_tail_index):\n",
    "        head2index[head] = index\n",
    "    relation = pd.unique(total_[2])\n",
    "    # create adj_list by using the index of each entity\n",
    "    exist_entity = set()\n",
    "    adj_ls = {}\n",
    "    for i in total_.iterrows():\n",
    "        if i[1][1] not in exist_entity:\n",
    "            adj_ls[head2index[i[1][1]]] = [head2index[i[1][3]]]\n",
    "            exist_entity.add(i[1][1])\n",
    "        else:\n",
    "            adj_ls[head2index[i[1][1]]].append(head2index[i[1][3]])\n",
    "    return adj_ls, head_tail.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0078e6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj_ls, num_nodes = build_adj_ls(total_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cfa44",
   "metadata": {},
   "source": [
    "## 创建edge index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b62a7",
   "metadata": {},
   "source": [
    "从adj_ls 里拿到edge index 的矩阵表示（shape为(2,num_edges)）:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c3e1f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edge_index(adj_ls, num_nodes,add_self_edges = True):\n",
    "    head_ids, tail_ids = [],[]\n",
    "    exist_edges = set()\n",
    "    for head, tails in adj_ls.items():\n",
    "        for tail in tails:\n",
    "            if (head, tail) not in exist_edges:\n",
    "                head_ids.append(head)\n",
    "                tail_ids.append(tail)\n",
    "                exist_edges.add((head,tail))\n",
    "    if add_self_edges:\n",
    "        head_ids.extend(np.arange(num_nodes))\n",
    "        tail_ids.extend(np.arange(num_nodes))\n",
    "    \n",
    "    # shape为(2,num_edges)\n",
    "    edge_idx = np.row_stack((head_ids, tail_ids))\n",
    "    return edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f7cf6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_idx=build_edge_index(adj_ls,num_nodes)\n",
    "edge_idx = torch.tensor(edge_idx,dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7a803e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 84574, 84575, 84576],\n",
       "        [  421,   422,   423,  ..., 84574, 84575, 84576]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf76284",
   "metadata": {},
   "source": [
    "## 初始化的embedding（待定，需要查阅维度(我这里就随机设了个5维)等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f0ee07b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_layer(nn.Module):\n",
    "    '''\n",
    "    implementation of GAT LAYER\n",
    "    '''\n",
    "    head_e_dim = 0\n",
    "    tail_dim = 1\n",
    "    \n",
    "    head_num_dim = 1\n",
    "    nodes_dim = 0\n",
    "    def __init__(self, feature_in, feature_out, num_heads, concat=True,dropout_prob = 0.6, activation = nn.ELU(),add_skip_connection =True, bias =True):\n",
    "        '''\n",
    "        input is:\n",
    "        1. in_feature shape\n",
    "        2. out_feature shape\n",
    "        3. multihead \n",
    "        4. concatenation \n",
    "        5. dropout rate\n",
    "        6. residual\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.feature_out = feature_out\n",
    "        self.concat = concat\n",
    "        self.act = activation\n",
    "        self.add_skip_connection = add_skip_connection\n",
    "        # 可以看为num_heads 个独立的W矩阵\n",
    "        self.ln1 = nn.Linear(feature_in, feature_out*num_heads,bias = False)\n",
    "        # apply additive attention \n",
    "        # 在concat的时候[x,y]分别代表节点的特征,即分别做两个变换后再加和\n",
    "        self.scoring_fn_head = nn.Parameter(torch.Tensor(1,num_heads, feature_out))\n",
    "        self.scoring_fn_tail = nn.Parameter(torch.Tensor(1,num_heads, feature_out))\n",
    "        \n",
    "        if bias and concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_heads*feature_out))\n",
    "        if not concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(feature_out))\n",
    "        if add_skip_connection:\n",
    "            self.ln2 = nn.Linear(feature_in, feature_out*num_heads, bias=False)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.init_params()\n",
    "    def init_params(self):\n",
    "        nn.init.xavier_uniform_(self.ln1.weight)\n",
    "        nn.init.xavier_uniform_(self.scoring_fn_head)\n",
    "        nn.init.xavier_uniform_(self.scoring_fn_tail)\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.zeros_(self.bias)\n",
    "        if self.add_skip_connection:\n",
    "            nn.init.xavier_uniform_(self.ln2.weight)\n",
    "    def lift(self, score_head, score_tail, features, edge_idx):\n",
    "        # 拿到edge对应的index\n",
    "        #edge_idx = torch.tensor(edge_idx,dtype=torch.long)\n",
    "        head_node_index = edge_idx[self.head_e_dim]\n",
    "        tail_node_index = edge_idx[self.tail_dim]\n",
    "        #通过edge index（实际上就是对应的node index）来拿到对应的分数,然后维度由N->E\n",
    "        score_head = score_head.index_select(self.nodes_dim,head_node_index)\n",
    "        score_tail = score_tail.index_select(self.nodes_dim, tail_node_index)\n",
    "        node_features_proj_lifted = features.index_select(self.nodes_dim,head_node_index)\n",
    "        return score_head, score_tail, node_features_proj_lifted\n",
    "    def broadcasting(self, entity_1, entity_2):\n",
    "        '''\n",
    "        扩开维度\n",
    "        '''\n",
    "        for i in range(entity_1.dim(),entity_2.dim()):\n",
    "            entity_1 = entity_1.unsqueeze(-1)\n",
    "        return entity_1.expand_as(entity_2)\n",
    "    def sum_edge_scores_neighbourhood(self, exp_scores_per_edge, tail_index,num_nodes):\n",
    "        '''\n",
    "        通过tail_index 和 原注意力exp_scores_per_edge 来进行汇聚 neighbour(scatter_add)\n",
    "        '''\n",
    "        trg_index_broadcast = self.broadcasting(tail_index, exp_scores_per_edge)\n",
    "        # shape = (N,NH)\n",
    "        size = list(exp_scores_per_edge.shape)\n",
    "        # 更改 nodes_dim\n",
    "        size[self.nodes_dim] = num_nodes\n",
    "        neighbour_sums = torch.zeros(size,dtype = exp_scores_per_edge.dtype,device = exp_scores_per_edge.device)\n",
    "        # 通过 scatter add, 输入是原矩阵, index矩阵和目标矩阵，目标矩阵的对应位置会是原矩阵的值的加和\n",
    "        neighbour_sums.scatter_add_(self.nodes_dim, trg_index_broadcast,exp_scores_per_edge)\n",
    "        return neighbour_sums.index_select(self.nodes_dim, tail_index)\n",
    "    def aggregate_neighbour_softmax(self, score_per_edge, tail_index,num_nodes):\n",
    "        '''\n",
    "        就是很简单的对邻居做aggregate\n",
    "        '''\n",
    "        scores_per_edge = score_per_edge - score_per_edge.max()#避免梯度炸裂\n",
    "        exp_scores_per_eg = scores_per_edge.exp()# softmax\n",
    "        neighbour_deno = self.sum_edge_scores_neighbourhood(exp_scores_per_eg,tail_index,num_nodes)\n",
    "        # cal attention\n",
    "        attention_per_edge = exp_scores_per_eg/(neighbour_deno+1e-16)\n",
    "        return attention_per_edge.unsqueeze(-1)\n",
    "    def aggregate_neighbours(self, node_feature_weighted, edge_index,in_features, num_nodes):\n",
    "        size = list(node_feature_weighted.shape)\n",
    "        size[self.nodes_dim] = num_nodes\n",
    "        out_node_features = torch.zeros(size, dtype = in_features.dtype, device = in_features.device)\n",
    "        \n",
    "        #broadcasting\n",
    "        tail_index_broadcast = self.broadcasting(edge_index[self.tail_dim],node_feature_weighted)\n",
    "        # accumulate all the attention head\n",
    "        out_node_features.scatter_add_(self.nodes_dim, tail_index_broadcast, node_feature_weighted)\n",
    "        return out_node_features\n",
    "    def residual_part(self, attention_coef, in_feature, out_feature):\n",
    "        if self.add_skip_connection:\n",
    "            if out_feature.shape[-1] == in_feature.shape[-1]:\n",
    "                #shape: (N,FIN)->(N,1,FIN), OUT: (N,NH,FOUT)\n",
    "                # 即将input vector扩大NH（num_head）次到outputvector里\n",
    "                out_feature += in_feature.unsqueeze(-1)\n",
    "            else:\n",
    "                # FIN!=FOUT\n",
    "                out_feature += self.ln2(in_feature).view(-1,self.num_heads, self.feature_out)\n",
    "        if self.concat:\n",
    "            # shape: (N,NH,FOUT)->(N, NH*FOUT)\n",
    "            out_feature = out_feature.view(-1,self.num_heads*self.feature_out)\n",
    "        else:\n",
    "            #shape: (N,NH,FOUT)->(N,FOUT),做avg\n",
    "            out_feature = out_feature.mean(dim = self.head_num_dim)\n",
    "        if self.bias is not None:\n",
    "            out_feature+= self.bias\n",
    "        return self.act(out_feature)\n",
    "    def forward(self, input_):\n",
    "        '''\n",
    "        input_ 是一个(nodefeatures, edge_index)的 二元组\n",
    "        '''\n",
    "        # 投影+正则化\n",
    "        node_features, edge_idx = input_\n",
    "        #edge_idx = torch.tensor(edge_idx,dtype= torch.long)\n",
    "        num_nodes = node_features.shape[self.nodes_dim]\n",
    "        # 保证 edge 的长是2\n",
    "        assert edge_idx.shape[0] ==2\n",
    "        node_features = self.dropout(node_features)\n",
    "        # 改变维度 (N, feature_in)*(feature_in, num_head*out)-> (N, nh, out)\n",
    "        node_features_proj = self.ln1(node_features).view(-1,self.num_heads, self.feature_out)\n",
    "        node_features_proj = self.dropout(node_features_proj)\n",
    "        # edge attention calculation 哈达玛积,按照最后一个维度求和\n",
    "        # shape (N,NH,OUT)*(1,NH,Fout) -> \n",
    "        score_head = (node_features_proj*self.scoring_fn_head).sum(dim=-1)\n",
    "        score_tail = (node_features_proj*self.scoring_fn_tail).sum(dim=-1)\n",
    "        # 使用lift函数拿到对应的score\n",
    "        score_head_lift, score_tail_lift, node_features_proj_lifted = self.lift(score_head, score_tail,node_features_proj, edge_idx)\n",
    "        scores_per_edge = self.leaky_relu(score_head_lift + score_tail_lift)\n",
    "        attention_per_edge = self.aggregate_neighbour_softmax(scores_per_edge,edge_idx[self.tail_dim], num_nodes)\n",
    "        attention_per_edge = self.dropout(attention_per_edge)\n",
    "        \n",
    "        # neighbour aggregation\n",
    "        # 拿到权重,这里的attention相当于将node feature当作value, edge当作key,邻居节点当作query\n",
    "        nodes_features_weighted = node_features_proj_lifted*attention_per_edge# 哈达玛积\n",
    "        out_node_feature = self.aggregate_neighbours(nodes_features_weighted,edge_idx,node_features,num_nodes)\n",
    "        \n",
    "        # done the residual part\n",
    "        out_node_feature = self.residual_part(attention_per_edge,node_features,out_node_feature)\n",
    "        return (out_node_feature, edge_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a4607f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142421, 2, 20]) torch.Size([1, 2, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([219341, 2]), torch.Size([219341, 2]), torch.Size([219341, 2, 20]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a test for lift function\n",
    "node_f = torch.rand(size = (142421,5))\n",
    "num_nodes = node_f.shape[0]\n",
    "assert edge_idx.shape[0] ==2\n",
    "ln = nn.Linear(5,20*2)\n",
    "node_f_proj = ln(node_f).view(-1, 2, 20)\n",
    "score_fn_head = nn.Parameter(torch.Tensor(1,2, 20))\n",
    "score_fn_tail = nn.Parameter(torch.Tensor(1,2,20))\n",
    "print(node_f_proj.shape,score_fn_head.shape)\n",
    "score_head = (node_f_proj*score_fn_head).sum(-1)\n",
    "score_tail = (node_f_proj*score_fn_tail).sum(-1)\n",
    "def lift(score_head, score_tail, features, edge_idx):\n",
    "        # 拿到edge对应的index\n",
    "        #edge_idx = torch.tensor(edge_idx,dtype=torch.long)\n",
    "        head_node_index = edge_idx[0]\n",
    "        tail_node_index = edge_idx[1]\n",
    "        #通过edge index（实际上就是对应的node index）来拿到对应的分数\n",
    "        score_head = score_head.index_select(0,head_node_index)\n",
    "        score_tail = score_tail.index_select(0, tail_node_index)\n",
    "        node_features_proj_lifted = features.index_select(0,head_node_index)\n",
    "        return score_head, score_tail, node_features_proj_lifted\n",
    "head,tail,feature= lift(score_head,score_tail,node_f_proj,edge_idx)\n",
    "head.shape, tail.shape, feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b9268afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3858, -0.1784, -0.3770,  ..., -0.0693,  0.8868, -0.1783],\n",
       "         [-0.5703,  0.0376, -0.5930,  ..., -0.4321, -0.3722,  0.6794],\n",
       "         [-0.6646,  0.1865,  0.1280,  ..., -0.2703, -0.3344,  0.7680],\n",
       "         ...,\n",
       "         [-0.0789, -0.1870,  0.3681,  ..., -0.1255, -0.0142,  0.1889],\n",
       "         [-0.0570,  0.1854, -0.1375,  ..., -0.0420, -0.1740,  0.1811],\n",
       "         [ 0.4217, -0.1616,  0.1986,  ...,  0.0410, -0.0907, -0.1615]],\n",
       "        grad_fn=<EluBackward0>),\n",
       " tensor([[    0,     0,     0,  ..., 84574, 84575, 84576],\n",
       "         [  421,   422,   423,  ..., 84574, 84575, 84576]]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a test for GAT layer\n",
    "feature_in, feature_out,num_heads = 5,20,2\n",
    "net = GAT_layer(feature_in,feature_out,num_heads)\n",
    "net((node_f,edge_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201dc712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
